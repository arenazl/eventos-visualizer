#!/usr/bin/env python3
"""
AnÃ¡lisis de tiempos de ejecuciÃ³n de scrapers
"""
import requests
import json
from datetime import datetime

def analyze_scrapers(location="Buenos Aires", limit=10):
    """Analiza los tiempos de ejecuciÃ³n de cada scraper"""
    
    print(f"\nğŸ” ANÃLISIS DE SCRAPERS - {datetime.now().strftime('%H:%M:%S')}")
    print("=" * 70)
    print(f"ğŸ“ UbicaciÃ³n: {location}")
    print(f"ğŸ“Š LÃ­mite: {limit} eventos por scraper")
    print("=" * 70)
    
    # Hacer request con detalles de scrapers
    url = f"http://172.29.228.80:8001/api/events?location={location}&limit={limit}&include_scrapers=true"
    
    try:
        response = requests.get(url, timeout=30)
        data = response.json()
        
        if 'scrapers_execution' in data:
            exec_data = data['scrapers_execution']
            
            print(f"\nğŸ“Š RESUMEN GENERAL:")
            print(f"  â€¢ Total de scrapers: {exec_data.get('total_scrapers', 0)}")
            print(f"  â€¢ Scrapers exitosos: {exec_data.get('successful_scrapers', 0)}")
            print(f"  â€¢ Tiempo total: {exec_data.get('total_time', 'N/A')}")
            print(f"  â€¢ Eventos totales: {data.get('total', 0)}")
            
            print(f"\nğŸ“‹ DETALLES POR SCRAPER:")
            print("-" * 70)
            print(f"{'Scraper':<25} {'Status':<10} {'Eventos':<10} {'Tiempo':<10} {'Mensaje'}")
            print("-" * 70)
            
            scrapers_info = exec_data.get('scrapers_info', [])
            
            # Ordenar por tiempo de respuesta
            scrapers_info.sort(key=lambda x: float(x.get('response_time', '0s').replace('s', '')), reverse=True)
            
            for scraper in scrapers_info:
                name = scraper.get('name', 'Unknown')
                status = scraper.get('status', 'unknown')
                events = scraper.get('events_count', 0)
                time = scraper.get('response_time', 'N/A')
                
                # Color coding por status
                if status == 'success':
                    icon = 'âœ…'
                elif status == 'timeout':
                    icon = 'â°'
                else:
                    icon = 'âŒ'
                
                print(f"{icon} {name:<23} {status:<10} {events:<10} {time:<10}", end="")
                
                if status != 'success' and 'message' in scraper:
                    msg = scraper['message'][:30]
                    print(f" {msg}...")
                else:
                    print()
            
            print("-" * 70)
            
            # AnÃ¡lisis de performance
            print(f"\nâš¡ ANÃLISIS DE PERFORMANCE:")
            
            successful = [s for s in scrapers_info if s.get('status') == 'success']
            failed = [s for s in scrapers_info if s.get('status') == 'failed']
            timeout = [s for s in scrapers_info if s.get('status') == 'timeout']
            
            if successful:
                times = [float(s.get('response_time', '0s').replace('s', '')) for s in successful]
                avg_time = sum(times) / len(times) if times else 0
                max_time = max(times) if times else 0
                min_time = min(times) if times else 0
                
                print(f"  â€¢ Tiempo promedio (exitosos): {avg_time:.2f}s")
                print(f"  â€¢ Tiempo mÃ¡ximo: {max_time:.2f}s")
                print(f"  â€¢ Tiempo mÃ­nimo: {min_time:.2f}s")
            
            if timeout:
                print(f"\nâš ï¸ TIMEOUTS DETECTADOS:")
                for s in timeout:
                    print(f"  â€¢ {s.get('name', 'Unknown')}: Timeout despuÃ©s de {s.get('response_time', 'N/A')}")
            
            if failed:
                print(f"\nâŒ SCRAPERS FALLIDOS:")
                for s in failed:
                    print(f"  â€¢ {s.get('name', 'Unknown')}: {s.get('message', 'Error desconocido')[:50]}...")
            
            # Identificar cuellos de botella
            print(f"\nğŸ”¥ CUELLOS DE BOTELLA IDENTIFICADOS:")
            bottlenecks = [s for s in scrapers_info if float(s.get('response_time', '0s').replace('s', '')) > 3.0]
            if bottlenecks:
                for s in bottlenecks:
                    print(f"  â€¢ {s.get('name', 'Unknown')}: {s.get('response_time', 'N/A')} (>3s)")
            else:
                print("  â€¢ No se detectaron scrapers lentos (>3s)")
            
        else:
            print("âš ï¸ No hay informaciÃ³n detallada de scrapers")
            print(f"Eventos encontrados: {data.get('total', 0)}")
            
    except requests.exceptions.Timeout:
        print("âŒ ERROR: Timeout al contactar el servidor (>30s)")
    except Exception as e:
        print(f"âŒ ERROR: {str(e)}")

if __name__ == "__main__":
    # Analizar con diferentes ciudades
    cities = ["Buenos Aires", "Madrid", "Barcelona", "Miami"]
    
    for city in cities:
        analyze_scrapers(city, limit=5)
        print("\n" + "="*70 + "\n")