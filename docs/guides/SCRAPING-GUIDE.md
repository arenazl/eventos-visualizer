<!-- AUDIT_HEADER
üïí √öLTIMA ACTUALIZACI√ìN: 2025-11-12 01:55
üìä STATUS: ACTIVE
üìù HISTORIAL:
- 2025-11-12 01:55: Creaci√≥n de gu√≠a completa de scraping
üìã TAGS: #scraping #guide #automation #eventos #apis
-->

# üï∑Ô∏è Gu√≠a Completa de Scraping de Eventos

Gu√≠a pr√°ctica paso a paso para obtener eventos de cualquier fuente y regi√≥n del mundo.

---

## üìã √çndice

1. [M√©todos de Scraping](#m√©todos-de-scraping)
2. [Estructura JSON Esperada](#estructura-json-esperada)
3. [M√©todo 1: APIs Oficiales](#m√©todo-1-apis-oficiales)
4. [M√©todo 2: Web Scraping con Puppeteer](#m√©todo-2-web-scraping-con-puppeteer)
5. [M√©todo 3: Gemini AI (Recomendado)](#m√©todo-3-gemini-ai-recomendado)
6. [Procesamiento Post-Scraping](#procesamiento-post-scraping)
7. [Mejores Pr√°cticas](#mejores-pr√°cticas)
8. [Troubleshooting](#troubleshooting)

---

## üéØ M√©todos de Scraping

### Comparaci√≥n R√°pida

| M√©todo | Calidad | Velocidad | Costo | Dificultad | Recomendado |
|--------|---------|-----------|-------|------------|-------------|
| **APIs Oficiales** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚ö°‚ö°‚ö° | üí∞üí∞ | üîß F√°cil | ‚úÖ Si hay API |
| **Web Scraping** | ‚≠ê‚≠ê‚≠ê | ‚ö°‚ö° | üí∞ | üîßüîßüîß Dif√≠cil | ‚ö†Ô∏è Si no hay API |
| **Gemini AI** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚ö°‚ö°‚ö°‚ö° | üí∞ Gratis | üîß Muy f√°cil | ‚úÖ‚úÖ **MEJOR** |

---

## üìÑ Estructura JSON Esperada

Todos los m√©todos deben generar JSONs con esta estructura:

### Estructura Base (Recomendada)

```json
{
  "ciudad": "Barcelona",
  "pais": "Espa√±a",
  "region": "Catalu√±a",
  "fecha_scraping": "2025-11-12T01:00:00",
  "eventos": [
    {
      "nombre": "Festival Primavera Sound 2025",
      "descripcion": "Festival de m√∫sica alternativa con artistas internacionales",
      "fecha_inicio": "2025-06-01",
      "fecha_fin": "2025-06-03",
      "venue": "Parc del F√≤rum",
      "direccion": "Parc del F√≤rum, Barcelona",
      "ciudad": "Barcelona",
      "pais": "Espa√±a",
      "categoria": "M√∫sica",
      "subcategoria": "Festival",
      "precio": "‚Ç¨280",
      "moneda": "EUR",
      "url": "https://primaverasound.com",
      "image_url": "",
      "latitud": 41.4099,
      "longitud": 2.2169,
      "source": "gemini_ai"
    }
  ]
}
```

### Estructura Alternativa (Array Simple)

```json
[
  {
    "titulo": "Concierto de Coldplay",
    "descripcion": "...",
    "fecha_inicio": "2025-12-15",
    "ciudad": "Madrid",
    "pais": "Espa√±a",
    "venue": "Estadio Santiago Bernab√©u",
    "precio": "‚Ç¨120",
    "url": "https://...",
    "categoria": "M√∫sica"
  }
]
```

### Campos Obligatorios

| Campo | Tipo | Descripci√≥n | Ejemplo |
|-------|------|-------------|---------|
| `nombre/titulo` | string | Nombre del evento | "Festival de Jazz 2025" |
| `fecha_inicio` | string | Fecha ISO o DD/MM/YYYY | "2025-11-20" |
| `ciudad` | string | Ciudad del evento | "Barcelona" |
| `pais` | string | Pa√≠s del evento | "Espa√±a" |

### Campos Opcionales (Pero Recomendados)

| Campo | Tipo | Descripci√≥n |
|-------|------|-------------|
| `descripcion` | string | Descripci√≥n del evento |
| `fecha_fin` | string | Fecha de finalizaci√≥n |
| `venue` | string | Lugar/recinto |
| `direccion` | string | Direcci√≥n completa |
| `categoria` | string | M√∫sica, Deportes, Cultural, Tech, etc. |
| `precio` | string | Precio en texto o n√∫mero |
| `moneda` | string | EUR, USD, ARS, etc. |
| `url` | string | URL oficial del evento |
| `image_url` | string | URL de imagen (se agrega despu√©s) |
| `latitud` | float | Coordenadas GPS |
| `longitud` | float | Coordenadas GPS |

---

## üîß M√©todo 1: APIs Oficiales

### Ventajas
- ‚úÖ Datos estructurados y confiables
- ‚úÖ Actualizaci√≥n en tiempo real
- ‚úÖ Im√°genes oficiales incluidas
- ‚úÖ Legal y permitido

### Desventajas
- ‚ùå Requiere API key (a veces de pago)
- ‚ùå Rate limiting (l√≠mites de requests)
- ‚ùå Solo cubre eventos de esa plataforma

### APIs Recomendadas

#### 1. Eventbrite API
**Cobertura**: Global, 180+ pa√≠ses

```bash
# Obtener API key:
# 1. Ir a https://www.eventbrite.com/platform/api
# 2. Crear app
# 3. Copiar Private Token

# Configurar en .env:
EVENTBRITE_API_KEY=tu_api_key_aqui
```

**Ejemplo de Request**:
```bash
curl -X GET "https://www.eventbriteapi.com/v3/events/search/?location.address=Barcelona&expand=venue,category" \
  -H "Authorization: Bearer YOUR_API_KEY"
```

#### 2. Ticketmaster Discovery API
**Cobertura**: USA, Canad√°, Europa, M√©xico

```bash
# Obtener API key:
# 1. Ir a https://developer.ticketmaster.com/
# 2. Registrarse
# 3. Crear app
# 4. Copiar API Key

# Configurar en .env:
TICKETMASTER_API_KEY=tu_api_key_aqui
```

**Ejemplo de Request**:
```bash
curl "https://app.ticketmaster.com/discovery/v2/events.json?city=Madrid&apikey=YOUR_API_KEY"
```

#### 3. Meetup API
**Cobertura**: Global (eventos comunitarios)

**Ejemplo**: Ver `backend/services/meetup_scraper.py`

### Script de Ejemplo (Eventbrite)

```python
import requests
import json
from datetime import datetime

def scrape_eventbrite(city, country_code='ES'):
    """
    Scrape eventos de Eventbrite

    Args:
        city: Ciudad (ej: "Barcelona")
        country_code: C√≥digo pa√≠s ISO (ej: "ES")

    Returns:
        dict: JSON con estructura esperada
    """
    api_key = os.getenv('EVENTBRITE_API_KEY')
    url = 'https://www.eventbriteapi.com/v3/events/search/'

    params = {
        'location.address': f"{city}, {country_code}",
        'location.within': '25km',
        'expand': 'venue,category',
        'page_size': 50
    }

    headers = {
        'Authorization': f'Bearer {api_key}'
    }

    response = requests.get(url, params=params, headers=headers)
    data = response.json()

    eventos = []
    for event in data.get('events', []):
        evento = {
            'nombre': event['name']['text'],
            'descripcion': event['description']['text'][:500],
            'fecha_inicio': event['start']['local'],
            'fecha_fin': event['end']['local'],
            'venue': event['venue']['name'] if event.get('venue') else '',
            'direccion': event['venue']['address']['localized_address_display'] if event.get('venue') else '',
            'ciudad': city,
            'pais': country_code,
            'categoria': event['category']['name'] if event.get('category') else 'General',
            'precio': 'Consultar',
            'url': event['url'],
            'image_url': event['logo']['url'] if event.get('logo') else '',
            'source': 'eventbrite_api'
        }
        eventos.append(evento)

    return {
        'ciudad': city,
        'pais': country_code,
        'fecha_scraping': datetime.now().isoformat(),
        'eventos': eventos
    }

# Uso:
resultado = scrape_eventbrite('Barcelona', 'ES')

# Guardar:
with open(f"barcelona_eventbrite_{datetime.now().strftime('%Y%m%d')}.json", 'w', encoding='utf-8') as f:
    json.dump(resultado, f, indent=2, ensure_ascii=False)
```

---

## üåê M√©todo 2: Web Scraping con Puppeteer

### Cu√°ndo Usar
- ‚ö†Ô∏è Solo si NO existe API oficial
- ‚ö†Ô∏è Para sitios espec√≠ficos de eventos locales
- ‚ö†Ô∏è Requiere mantenimiento (cambios en el sitio rompen el scraper)

### Herramientas Necesarias

```bash
# Instalar Node.js y dependencias
npm install puppeteer axios cheerio

# O usar Playwright
pip install playwright
playwright install chromium
```

### Script de Ejemplo (Puppeteer)

```javascript
const puppeteer = require('puppeteer');
const fs = require('fs');

async function scrapeSitioLocal(url, ciudad, pais) {
    const browser = await puppeteer.launch({
        headless: true,
        args: ['--no-sandbox']
    });

    const page = await browser.newPage();
    await page.goto(url, { waitUntil: 'networkidle2' });

    // Extraer eventos (adaptar selectores seg√∫n sitio)
    const eventos = await page.evaluate(() => {
        const items = Array.from(document.querySelectorAll('.event-item'));

        return items.map(item => ({
            nombre: item.querySelector('.event-title')?.innerText || '',
            descripcion: item.querySelector('.event-description')?.innerText || '',
            fecha_inicio: item.querySelector('.event-date')?.innerText || '',
            venue: item.querySelector('.event-venue')?.innerText || '',
            precio: item.querySelector('.event-price')?.innerText || 'Gratis',
            url: item.querySelector('a')?.href || ''
        }));
    });

    await browser.close();

    // Estructura final
    const resultado = {
        ciudad: ciudad,
        pais: pais,
        fecha_scraping: new Date().toISOString(),
        eventos: eventos.map(e => ({
            ...e,
            ciudad: ciudad,
            pais: pais,
            source: 'web_scraping'
        }))
    };

    // Guardar
    fs.writeFileSync(
        `${ciudad.toLowerCase()}_${Date.now()}.json`,
        JSON.stringify(resultado, null, 2)
    );

    console.log(`‚úÖ ${eventos.length} eventos scrapeados de ${ciudad}`);
    return resultado;
}

// Uso:
scrapeSitioLocal('https://ejemplo-eventos.com/barcelona', 'Barcelona', 'Espa√±a');
```

### Desaf√≠os Comunes

1. **Selectores cambian**: Sitios web cambian su HTML
2. **Rate limiting**: Bloqueos por demasiadas requests
3. **JavaScript din√°mico**: Contenido cargado async
4. **CAPTCHAs**: Protecci√≥n anti-bot

**Soluci√≥n**: Usar M√©todo 3 (Gemini AI) en su lugar.

---

## ü§ñ M√©todo 3: Gemini AI (Recomendado)

### ¬øPor Qu√© Es el Mejor?

- ‚úÖ **Gratis**: Sin API keys de pago
- ‚úÖ **R√°pido**: Obtiene eventos de cualquier ciudad en segundos
- ‚úÖ **Inteligente**: Entiende contexto local y encuentra eventos actuales
- ‚úÖ **Sin mantenimiento**: No depende de HTML/selectores
- ‚úÖ **Global**: Funciona para cualquier ciudad del mundo

### Limitaciones

- ‚ö†Ô∏è L√≠mite de ~10 b√∫squedas por sesi√≥n (pausa 2-4 horas despu√©s)
- ‚ö†Ô∏è Calidad variable (revisar eventos generados)
- ‚ö†Ô∏è Fechas a veces gen√©ricas (requiere curaci√≥n)

### M√©todo Manual (Gemini Web)

#### Paso 1: Ir a Gemini

Acceder a **Gemini** en cualquiera de estas URLs:
- https://gemini.google.com (oficial)
- https://gemini.com (redirect)

O simplemente buscar "Gemini" en Google.

#### Paso 2: Prompt Optimizado

```
Dame 20 eventos reales pr√≥ximos en [CIUDAD], [PA√çS] en los pr√≥ximos 30 d√≠as.

Incluye solo eventos confirmados con:
- Nombre exacto del evento
- Fecha espec√≠fica (d√≠a/mes/a√±o)
- Lugar/venue espec√≠fico
- Breve descripci√≥n
- Categor√≠a (M√∫sica, Deportes, Cultural, Tech, Fiestas)
- Precio aproximado

Formato JSON:
{
  "ciudad": "[CIUDAD]",
  "pais": "[PA√çS]",
  "eventos": [
    {
      "nombre": "...",
      "fecha_inicio": "YYYY-MM-DD",
      "venue": "...",
      "descripcion": "...",
      "categoria": "...",
      "precio": "..."
    }
  ]
}
```

**Ejemplo Real**:
```
Dame 20 eventos reales pr√≥ximos en Barcelona, Espa√±a en los pr√≥ximos 30 d√≠as.

Incluye solo eventos confirmados con fecha espec√≠fica, lugar y descripci√≥n.

Formato JSON con campos: nombre, fecha_inicio, venue, descripcion, categoria, precio
```

#### Paso 3: Copiar Respuesta

Gemini responder√° con algo como:

```json
{
  "ciudad": "Barcelona",
  "pais": "Espa√±a",
  "eventos": [
    {
      "nombre": "Primavera Sound 2025",
      "fecha_inicio": "2025-06-01",
      "venue": "Parc del F√≤rum",
      "descripcion": "Festival de m√∫sica alternativa con The Strokes, Lorde...",
      "categoria": "M√∫sica",
      "precio": "‚Ç¨280"
    },
    {
      "nombre": "FC Barcelona vs Real Madrid - El Cl√°sico",
      "fecha_inicio": "2025-11-25",
      "venue": "Camp Nou",
      "descripcion": "Partido de LaLiga entre los dos grandes rivales",
      "categoria": "Deportes",
      "precio": "‚Ç¨150-500"
    }
  ]
}
```

#### Paso 4: Guardar JSON

```bash
# Crear archivo
nano barcelona_noviembre.json

# Pegar contenido
# Ctrl+O para guardar
# Ctrl+X para salir
```

### M√©todo Automatizado (Playwright + Gemini)

**Script**: `backend/scripts/gemini_scraper_automated.py`

```bash
# Instalar dependencias
pip install playwright python-dotenv
playwright install chromium

# Configurar credenciales Google
# Editar .env:
GOOGLE_EMAIL=tu_email@gmail.com
GOOGLE_PASSWORD=tu_password

# Ejecutar
cd backend/scripts
python gemini_scraper_automated.py
```

**El script**:
1. Abre Gemini Web en navegador headless
2. Hace login autom√°tico
3. Env√≠a prompt para cada ciudad
4. Extrae JSON de respuesta
5. Guarda en `backend/data/ai_scraped/`

### Curaci√≥n Post-Gemini

**IMPORTANTE**: Eventos de Gemini pueden ser gen√©ricos o con fechas aproximadas.

**Script de Curaci√≥n**: `backend/automation/curate_ai_events.py`

```bash
cd backend
python automation/curate_ai_events.py --input data/ai_scraped --output data/curated
```

**Qu√© hace**:
- ‚úÖ Valida que eventos tengan fecha espec√≠fica
- ‚úÖ Elimina eventos con nombres gen√©ricos ("Concierto de m√∫sica")
- ‚úÖ Detecta duplicados (85% similitud)
- ‚úÖ Agrega im√°genes autom√°ticamente
- ‚úÖ Normaliza formato para DB

---

## ‚öôÔ∏è Procesamiento Post-Scraping

### Paso 1: Agregar Im√°genes Reales

**NUNCA usar Unsplash/Pexels gen√©ricos**. Usar Google Images con t√≠tulo exacto.

```bash
cd backend/data/scripts
node add_images_generic.js scrapper_results/europa
```

**Resultado**:
- Busca cada evento en Google Images
- Extrae primera imagen JPG real
- Agrega campo `image_url` al JSON
- Pausa 2 seg entre requests (evita rate limit)

### Paso 2: Importar a MySQL

```bash
cd backend/data/scripts
python import_generic.py scrapper_results/europa
```

**Resultado**:
- Lee todos los JSONs recursivamente
- Normaliza datos (fechas, precios, categor√≠as)
- Verifica duplicados (t√≠tulo + ciudad + fecha)
- Inserta solo eventos nuevos
- Reporta estad√≠sticas

### Paso 3: Verificar Importaci√≥n

```sql
-- En MySQL
SELECT
  city,
  COUNT(*) as total_eventos,
  SUM(CASE WHEN image_url IS NOT NULL THEN 1 ELSE 0 END) as con_imagen
FROM events
GROUP BY city
ORDER BY total_eventos DESC;
```

---

## üìä Workflow Completo Recomendado

### Para Una Ciudad Nueva

```bash
# 1. Scrapear con Gemini (manual o automatizado)
# ‚Üí Genera: barcelona_noviembre.json

# 2. Guardar en estructura correcta
mkdir -p backend/data/scrapper_results/europa/europa-meridional/espana/2025-11
mv barcelona_noviembre.json backend/data/scrapper_results/europa/europa-meridional/espana/2025-11/

# 3. Agregar im√°genes reales
cd backend/data/scripts
node add_images_generic.js scrapper_results/europa/europa-meridional/espana/2025-11

# 4. Importar a MySQL
python import_generic.py scrapper_results/europa/europa-meridional/espana/2025-11

# 5. Verificar en base de datos
mysql -u root -p eventos_visualizer -e "SELECT COUNT(*) FROM events WHERE city='Barcelona';"
```

### Para M√∫ltiples Ciudades (Regi√≥n Completa)

```bash
# 1. Scrapear todas las ciudades (Gemini automatizado recomendado)
cd backend/scripts
python gemini_scraper_automated.py
# ‚Üí Genera m√∫ltiples JSONs en data/ai_scraped/

# 2. Curar eventos
cd backend
python automation/curate_ai_events.py --input data/ai_scraped --output data/curated

# 3. Mover a estructura correcta
# (Organizar manualmente en scrapper_results/region/pais/mes/)

# 4. Agregar im√°genes a TODA la regi√≥n
cd backend/data/scripts
node add_images_generic.js scrapper_results/europa

# 5. Importar TODO
python import_generic.py scrapper_results/europa
```

---

## üéØ Mejores Pr√°cticas

### 1. Nombrado de Archivos

```
‚úÖ BIEN:
barcelona_noviembre.json
madrid_2025-11.json
paris_noviembre_2025.json

‚ùå MAL:
eventos.json
data.json
scraping_final_v2_real.json
```

### 2. Organizaci√≥n de Carpetas

```
‚úÖ BIEN:
scrapper_results/
‚îî‚îÄ‚îÄ europa/
    ‚îî‚îÄ‚îÄ europa-meridional/
        ‚îî‚îÄ‚îÄ espana/
            ‚îî‚îÄ‚îÄ 2025-11/
                ‚îú‚îÄ‚îÄ barcelona_noviembre.json
                ‚îú‚îÄ‚îÄ madrid_noviembre.json
                ‚îî‚îÄ‚îÄ valencia_noviembre.json

‚ùå MAL:
data/
‚îú‚îÄ‚îÄ barcelona.json
‚îú‚îÄ‚îÄ madrid.json
‚îî‚îÄ‚îÄ todos_eventos_europa_final.json
```

### 3. Frecuencia de Scraping

- **APIs**: Diario (si hay rate limit generoso)
- **Web Scraping**: Semanal (evita bloqueos)
- **Gemini AI**: Por demanda (l√≠mite de sesi√≥n)

### 4. Validaci√≥n de Datos

**SIEMPRE validar antes de importar**:

```python
def validar_evento(evento):
    """Valida que evento tenga datos m√≠nimos"""
    if not evento.get('nombre') or not evento.get('titulo'):
        return False

    if not evento.get('fecha_inicio'):
        return False

    if not evento.get('ciudad') or not evento.get('city'):
        return False

    # Detectar eventos gen√©ricos
    nombres_genericos = ['evento', 'concierto', 'festival', 'partido']
    nombre_lower = evento.get('nombre', '').lower()
    if nombre_lower in nombres_genericos:
        return False

    return True
```

### 5. Detecci√≥n de Duplicados

**En la base de datos**:
```sql
-- Verificar duplicados antes de importar
SELECT title, city, DATE(start_datetime), COUNT(*)
FROM events
GROUP BY title, city, DATE(start_datetime)
HAVING COUNT(*) > 1;
```

**En los scripts** (ya implementado en `import_generic.py`):
- Verificar t√≠tulo + ciudad + fecha
- Solo insertar si no existe

---

## üõ†Ô∏è Troubleshooting

### Problema 1: Gemini da eventos gen√©ricos

**S√≠ntoma**:
```json
{
  "nombre": "Concierto de m√∫sica",
  "fecha_inicio": "Pr√≥ximamente"
}
```

**Soluci√≥n**:
- Mejorar prompt: "Dame EVENTOS CONFIRMADOS con FECHA ESPEC√çFICA"
- Agregar: "Incluye nombre exacto del artista/equipo"
- Pausar sesi√≥n (l√≠mite de 10 b√∫squedas alcanzado)

### Problema 2: Rate Limiting de Google Images

**S√≠ntoma**: Muchos eventos con "‚ö†Ô∏è Solo logo de Google"

**Soluci√≥n**:
```javascript
// En add_images_generic.js, aumentar pausa:
await new Promise(resolve => setTimeout(resolve, 4000)); // De 2000 a 4000ms
```

### Problema 3: Eventos duplicados en DB

**S√≠ntoma**: `import_generic.py` reporta "0 insertados, 100 duplicados"

**Causa**: Eventos ya existen en base de datos

**Verificar**:
```bash
python import_generic.py scrapper_results/europa 2>&1 | grep "duplicados"
```

**Si son duplicados reales**: ‚úÖ Todo bien, script funciona correctamente

**Si deber√≠an ser nuevos**: Revisar criterio de duplicados (t√≠tulo + ciudad + fecha)

### Problema 4: Im√°genes no se agregan

**S√≠ntoma**: `add_images_generic.js` reporta "0 actualizados"

**Causas posibles**:
1. Eventos ya tienen `image_url`
2. Estructura JSON no reconocida
3. Error en m√≥dulo `buscar-primera-imagen.js`

**Debug**:
```bash
node -e "
const data = require('./ruta/al/archivo.json');
const eventos = data.eventos || data;
console.log('Total eventos:', eventos.length);
console.log('Sin imagen:', eventos.filter(e => !e.image_url).length);
"
```

### Problema 5: Script de importaci√≥n falla

**S√≠ntoma**: Error de MySQL connection

**Soluci√≥n**:
```python
# Verificar credenciales en import_generic.py:
DB_CONFIG = {
    'host': 'localhost',  # O tu host
    'user': 'root',       # Tu usuario
    'password': 'TuPassword',  # CAMBIAR ESTO
    'database': 'eventos_visualizer',
    'charset': 'utf8mb4'
}
```

---

## üìö Recursos Adicionales

### Documentaci√≥n Relacionada

- `backend/data/scripts/README.md` - Gu√≠a de scripts gen√©ricos
- `docs/00-INDEX.md` - √çndice maestro de documentaci√≥n
- `PROGRESS_SCRAPING.md` - Progreso de scraping Am√©rica Latina
- `docs/scraping-gemini-progress.md` - Progreso Gemini AI

### APIs de Eventos

- **Eventbrite**: https://www.eventbrite.com/platform/api
- **Ticketmaster**: https://developer.ticketmaster.com/
- **Meetup**: https://www.meetup.com/api/
- **Facebook Events**: https://developers.facebook.com/docs/graph-api/reference/event/

### Herramientas de Scraping

- **Puppeteer**: https://pptr.dev/
- **Playwright**: https://playwright.dev/
- **Beautiful Soup**: https://www.crummy.com/software/BeautifulSoup/
- **Scrapy**: https://scrapy.org/

### Gemini AI

- **Gemini Web**: https://gemini.google.com
- **Gemini API**: https://ai.google.dev/

---

## üéØ Checklist de Scraping

Usa esto cada vez que scrapes una nueva regi√≥n:

- [ ] **Elegir m√©todo** (API > Gemini AI > Web Scraping)
- [ ] **Preparar prompt/script** seg√∫n m√©todo
- [ ] **Scrapear eventos** (m√≠nimo 10-15 por ciudad)
- [ ] **Guardar JSON** en estructura correcta (`scrapper_results/`)
- [ ] **Validar estructura** (campos obligatorios presentes)
- [ ] **Curar datos** (si es Gemini AI)
- [ ] **Agregar im√°genes** (`node add_images_generic.js`)
- [ ] **Importar a MySQL** (`python import_generic.py`)
- [ ] **Verificar en DB** (count de eventos y con imagen)
- [ ] **Documentar progreso** (actualizar PROGRESS_SCRAPING.md)

---

## üöÄ Pr√≥ximos Pasos

1. **Automatizaci√≥n completa**: Script maestro que ejecute todo el pipeline
2. **Scheduler**: Cron job para scraping diario/semanal
3. **Monitoring**: Alertas de eventos nuevos
4. **Cach√© inteligente**: Evitar re-scrapear eventos ya procesados
5. **Multi-source**: Combinar APIs + Gemini para m√°xima cobertura

---

**√öltima actualizaci√≥n**: 2025-11-12
**Pr√≥xima revisi√≥n**: Despu√©s de automatizar pipeline completo
