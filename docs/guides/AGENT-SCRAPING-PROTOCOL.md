<!-- AUDIT_HEADER
ðŸ•’ ÃšLTIMA ACTUALIZACIÃ“N: 2025-11-12 02:05
ðŸ“Š STATUS: ACTIVE
ðŸ“ HISTORIAL:
- 2025-11-12 02:05: CreaciÃ³n de protocolo de scraping para agentes
ðŸ“‹ TAGS: #agent #protocol #scraping #automation #step-by-step
-->

# ðŸ¤– PROTOCOLO DE SCRAPING PARA AGENTES

**PropÃ³sito**: GuÃ­a paso a paso para que un agente ejecute el proceso completo de scraping de eventos.

**Input**: Lista de ciudades a scrapear
**Output**: Eventos en MySQL con imÃ¡genes reales

---

## ðŸ“‹ PUNTO DE ENTRADA

El usuario proporciona una lista de ciudades en este formato:

```
Ciudad, PaÃ­s
```

**Ejemplo:**
```
ParÃ­s, Francia
Barcelona, EspaÃ±a
Roma, Italia
BerlÃ­n, Alemania
```

**LÃ­mite recomendado**: 7-8 ciudades por sesiÃ³n (limitaciÃ³n de Gemini)

---

## ðŸŽ¯ PROCESO COMPLETO

### ETAPA 1: PREPARACIÃ“N

**Objetivo**: Verificar estructura y preparar entorno

**Acciones**:

1. **Verificar estructura de carpetas existe**:
   ```bash
   ls -la C:\Code\eventos-visualizer\backend\data\scrapper_results
   ```

2. **Para cada ciudad, determinar ruta de guardado**:
   - Europa â†’ `scrapper_results/europa/[regiÃ³n]/[paÃ­s]/2025-11/`
   - LatinoamÃ©rica â†’ `scrapper_results/latinamerica/[regiÃ³n]/[paÃ­s]/2025-11/`
   - NorteamÃ©rica â†’ `scrapper_results/norteamerica/norteamerica/[paÃ­s]/2025-11/`

3. **Crear carpetas si no existen**:
   ```bash
   mkdir -p "ruta/completa/determinada"
   ```

**Ejemplo para ParÃ­s, Francia**:
```bash
mkdir -p "C:\Code\eventos-visualizer\backend\data\scrapper_results\europa\europa-occidental\francia\2025-11"
```

**Criterio de Ã©xito**: Carpetas creadas y verificadas

---

### ETAPA 2: SCRAPING CON GEMINI

**Objetivo**: Obtener eventos de cada ciudad usando Gemini Web

**MÃ©todo**: Manual (el agente guÃ­a al usuario)

**Acciones para CADA ciudad**:

1. **Informar al usuario**:
   ```
   ðŸ” Scrapeando: [CIUDAD], [PAÃS]
   ðŸ“‚ GuardarÃ¡ en: [RUTA]
   ```

2. **Proporcionar prompt para Gemini**:
   ```
   Ve a: https://gemini.com

   Usa este prompt:

   ---
   Dame 20-30 eventos reales y confirmados en [CIUDAD], [PAÃS] para los prÃ³ximos 30 dÃ­as (noviembre-diciembre 2025).

   IMPORTANTE:
   - Solo eventos CONFIRMADOS con fecha especÃ­fica
   - Incluye nombre exacto del evento (no genÃ©ricos como "concierto de mÃºsica")
   - Fecha en formato YYYY-MM-DD
   - Lugar/venue especÃ­fico
   - DescripciÃ³n breve
   - CategorÃ­a (MÃºsica, Deportes, Cultural, Tech, Fiestas)
   - Precio aproximado

   Responde SOLO con JSON en este formato:
   {
     "ciudad": "[CIUDAD]",
     "pais": "[PAÃS]",
     "fecha_scraping": "2025-11-12T00:00:00",
     "eventos": [
       {
         "nombre": "Nombre exacto del evento",
         "descripcion": "DescripciÃ³n del evento",
         "fecha_inicio": "2025-11-20",
         "fecha_fin": "2025-11-20",
         "venue": "Nombre del lugar",
         "direccion": "DirecciÃ³n completa",
         "ciudad": "[CIUDAD]",
         "pais": "[PAÃS]",
         "categoria": "MÃºsica",
         "subcategoria": "Rock",
         "precio": "â‚¬50",
         "moneda": "EUR",
         "url": "https://...",
         "source": "gemini_ai"
       }
     ]
   }
   ---
   ```

3. **Esperar que el usuario copie la respuesta de Gemini**

4. **Crear archivo JSON**:
   ```bash
   # Nombre: ciudad_noviembre.json (todo en minÃºsculas, sin espacios)
   # Ejemplo: paris_noviembre.json
   ```

5. **Escribir contenido**:
   - Usar herramienta Write
   - Ruta completa: `[ruta_determinada]/[ciudad]_noviembre.json`
   - Contenido: JSON copiado de Gemini

6. **Validar JSON**:
   ```bash
   python -m json.tool [ruta_al_archivo.json]
   ```
   Si hay error de formato, corregir.

**Criterio de Ã©xito**:
- âœ… Archivo JSON creado
- âœ… JSON vÃ¡lido (sin errores de sintaxis)
- âœ… MÃ­nimo 10 eventos por ciudad
- âœ… Eventos tienen campos obligatorios (nombre, fecha, ciudad)

**Contador de sesiÃ³n**: Llevar cuenta de ciudades scrapeadas. Si llega a 8, PAUSAR y avisar:
```
âš ï¸ Alcanzado lÃ­mite de Gemini (8 bÃºsquedas)
â¸ï¸ Se recomienda pausar 2-4 horas antes de continuar
ðŸ“Š Progreso: [X]/[TOTAL] ciudades completadas
```

---

### ETAPA 3: AGREGAR IMÃGENES REALES

**Objetivo**: Agregar `image_url` a cada evento usando Google Images

**MÃ©todo**: Script genÃ©rico de Node.js

**Acciones**:

1. **Determinar scope** (Â¿una ciudad, un paÃ­s, toda la regiÃ³n?):
   - Una ciudad: Ruta especÃ­fica al mes
   - Un paÃ­s: Ruta al paÃ­s
   - Toda regiÃ³n: Ruta a regiÃ³n (europa, latinamerica, etc.)

2. **Ejecutar script de imÃ¡genes**:
   ```bash
   cd C:\Code\eventos-visualizer\backend\data\scripts
   node add_images_generic.js [ruta_relativa]
   ```

   **Ejemplos**:
   ```bash
   # Una ciudad especÃ­fica
   node add_images_generic.js scrapper_results/europa/europa-occidental/francia/2025-11

   # Todo un paÃ­s
   node add_images_generic.js scrapper_results/europa/europa-occidental/francia

   # Toda Europa
   node add_images_generic.js scrapper_results/europa
   ```

3. **Monitorear salida**:
   - Contar eventos actualizados
   - Detectar errores (rate limiting, etc.)
   - Si hay muchos errores: pausar o reducir scope

4. **Verificar resultado**:
   ```bash
   # Contar eventos con imagen agregada
   grep -r "image_url" [ruta] | grep -v '""' | wc -l
   ```

**Criterio de Ã©xito**:
- âœ… MÃ­nimo 70% de eventos tienen `image_url`
- âœ… URLs no son logos de Google (`gstatic`)
- âœ… Script completÃ³ sin errores crÃ­ticos

**Tiempo estimado**: 2 segundos por evento (pausa anti-rate-limit)

---

### ETAPA 4: IMPORTAR A MYSQL

**Objetivo**: Insertar eventos en base de datos con detecciÃ³n de duplicados

**MÃ©todo**: Script genÃ©rico de Python

**Acciones**:

1. **Verificar conexiÃ³n MySQL**:
   ```bash
   python -c "import pymysql; pymysql.connect(host='localhost', user='root', password='Look2025', database='eventos_visualizer'); print('âœ… MySQL OK')"
   ```

2. **Ejecutar importador**:
   ```bash
   cd C:\Code\eventos-visualizer\backend\data\scripts
   python import_generic.py [ruta_relativa]
   ```

   **Ejemplos**:
   ```bash
   # Una ciudad
   python import_generic.py scrapper_results/europa/europa-occidental/francia/2025-11

   # Todo un paÃ­s
   python import_generic.py scrapper_results/europa/europa-occidental/francia

   # Toda Europa
   python import_generic.py scrapper_results/europa
   ```

3. **Analizar salida**:
   - Eventos insertados (nuevos)
   - Eventos duplicados (ya existÃ­an)
   - Errores (si los hay)

4. **Verificar en base de datos**:
   ```sql
   SELECT
     city,
     COUNT(*) as total,
     SUM(CASE WHEN image_url IS NOT NULL THEN 1 ELSE 0 END) as con_imagen,
     ROUND(SUM(CASE WHEN image_url IS NOT NULL THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 1) as porcentaje_imagen
   FROM events
   WHERE city IN ('Paris', 'Barcelona', 'Roma')
   GROUP BY city;
   ```

**Criterio de Ã©xito**:
- âœ… Eventos insertados > 0 (si son nuevos)
- âœ… Tasa de Ã©xito > 80%
- âœ… Errores < 20%
- âœ… Eventos tienen `image_url` en DB

---

### ETAPA 5: REPORTE FINAL

**Objetivo**: Informar al usuario del resultado completo

**Acciones**:

1. **Calcular estadÃ­sticas totales**:
   ```sql
   SELECT
     COUNT(*) as total_eventos,
     COUNT(DISTINCT city) as ciudades,
     COUNT(DISTINCT country) as paises,
     SUM(CASE WHEN image_url IS NOT NULL THEN 1 ELSE 0 END) as con_imagen,
     MIN(start_datetime) as evento_mas_proximo,
     MAX(start_datetime) as evento_mas_lejano
   FROM events
   WHERE created_at >= CURDATE();
   ```

2. **Generar reporte**:
   ```markdown
   # ðŸ“Š Reporte de Scraping Completado

   **Fecha**: [FECHA]
   **Ciudades procesadas**: [X] ciudades

   ## Resultados por Ciudad

   | Ciudad | PaÃ­s | Eventos | Con Imagen | %   |
   |--------|------|---------|------------|-----|
   | ParÃ­s  | Francia | 25 | 23 | 92% |
   | ...    | ...     | ... | ... | ... |

   ## EstadÃ­sticas Globales

   - **Total eventos insertados**: [X]
   - **Total con imagen**: [X] ([X]%)
   - **Duplicados detectados**: [X]
   - **Errores**: [X]

   ## Archivos Generados

   - `scrapper_results/europa/.../paris_noviembre.json`
   - ...

   ## PrÃ³ximos Pasos

   - [ ] Verificar eventos en frontend
   - [ ] Revisar eventos sin imagen (si hay)
   - [ ] Documentar en PROGRESS_SCRAPING.md

   ## Notas

   [Cualquier observaciÃ³n relevante]
   ```

3. **Actualizar documentaciÃ³n de progreso**:
   - Agregar ciudades procesadas a `PROGRESS_SCRAPING.md`
   - Actualizar contador de regiones completadas
   - Marcar paÃ­ses completados si corresponde

**Criterio de Ã©xito**:
- âœ… Reporte generado y presentado al usuario
- âœ… DocumentaciÃ³n actualizada
- âœ… Usuario tiene visibilidad completa del resultado

---

## ðŸ”„ FLUJO COMPLETO RESUMIDO

```
ENTRADA: Lista de ciudades
    â†“
ETAPA 1: PreparaciÃ³n
    â†“ (crear carpetas)
ETAPA 2: Scraping con Gemini
    â†“ (generar JSONs, mÃ¡x 7-8 ciudades)
ETAPA 3: Agregar imÃ¡genes
    â†“ (Google Images real)
ETAPA 4: Importar a MySQL
    â†“ (con detecciÃ³n duplicados)
ETAPA 5: Reporte
    â†“
SALIDA: Eventos en DB + Reporte
```

---

## ðŸ“Š EJEMPLO COMPLETO

**Input del usuario**:
```
ParÃ­s, Francia
Lyon, Francia
Marsella, Francia
```

**EjecuciÃ³n del agente**:

### Paso 1: PreparaciÃ³n
```
âœ… Estructura verificada
ðŸ“‚ Creada: scrapper_results/europa/europa-occidental/francia/2025-11
```

### Paso 2: Scraping
```
ðŸ” Scrapeando 1/3: ParÃ­s, Francia
ðŸ“‹ Prompt proporcionado al usuario
â³ Esperando respuesta de Gemini...
âœ… JSON creado: paris_noviembre.json (28 eventos)

ðŸ” Scrapeando 2/3: Lyon, Francia
ðŸ“‹ Prompt proporcionado al usuario
â³ Esperando respuesta de Gemini...
âœ… JSON creado: lyon_noviembre.json (22 eventos)

ðŸ” Scrapeando 3/3: Marsella, Francia
ðŸ“‹ Prompt proporcionado al usuario
â³ Esperando respuesta de Gemini...
âœ… JSON creado: marsella_noviembre.json (25 eventos)

ðŸ“Š Total: 75 eventos en 3 archivos JSON
```

### Paso 3: ImÃ¡genes
```
ðŸ–¼ï¸ Agregando imÃ¡genes reales desde Google Images...
ðŸ“‚ Procesando: scrapper_results/europa/europa-occidental/francia/2025-11

âœ… paris_noviembre.json: 26/28 imÃ¡genes agregadas (92.8%)
âœ… lyon_noviembre.json: 20/22 imÃ¡genes agregadas (90.9%)
âœ… marsella_noviembre.json: 23/25 imÃ¡genes agregadas (92.0%)

ðŸ“Š Total: 69/75 eventos con imagen (92.0%)
```

### Paso 4: Import MySQL
```
ðŸ“¥ Importando a MySQL...
ðŸ“‚ Procesando: scrapper_results/europa/europa-occidental/francia/2025-11

âœ… paris_noviembre.json: 28 insertados, 0 duplicados
âœ… lyon_noviembre.json: 22 insertados, 0 duplicados
âœ… marsella_noviembre.json: 25 insertados, 0 duplicados

ðŸ“Š Total: 75 eventos insertados (100% Ã©xito)
```

### Paso 5: Reporte
```markdown
# ðŸ“Š Reporte de Scraping - Francia

**Fecha**: 2025-11-12
**Ciudades**: 3 (ParÃ­s, Lyon, Marsella)

## Resultados

| Ciudad   | Eventos | Con Imagen | %    |
|----------|---------|------------|------|
| ParÃ­s    | 28      | 26         | 92.8% |
| Lyon     | 22      | 20         | 90.9% |
| Marsella | 25      | 23         | 92.0% |

## Totales

- âœ… **75 eventos** insertados
- âœ… **69 eventos** con imagen (92.0%)
- âœ… **0 duplicados**
- âœ… **0 errores**

## Archivos

- `scrapper_results/europa/europa-occidental/francia/2025-11/paris_noviembre.json`
- `scrapper_results/europa/europa-occidental/francia/2025-11/lyon_noviembre.json`
- `scrapper_results/europa/europa-occidental/francia/2025-11/marsella_noviembre.json`

ðŸŽ‰ Proceso completado exitosamente!
```

---

## âš ï¸ MANEJO DE ERRORES

### Error: LÃ­mite de Gemini alcanzado

**SÃ­ntoma**: Gemini da respuestas genÃ©ricas o sin fechas especÃ­ficas

**AcciÃ³n**:
1. PAUSAR inmediatamente
2. Informar al usuario:
   ```
   âš ï¸ LÃ­mite de Gemini alcanzado despuÃ©s de [X] ciudades
   â¸ï¸ Se procesaron: [lista de ciudades completadas]
   â³ Pendientes: [lista de ciudades faltantes]
   ðŸ’¡ RecomendaciÃ³n: Pausar 2-4 horas y continuar con las pendientes
   ```
3. Completar Etapas 3-5 con las ciudades ya scrapeadas
4. NO continuar scrapeando con Gemini degradado

### Error: Rate limiting de Google Images

**SÃ­ntoma**: Muchos eventos consecutivos sin imagen ("Solo logo de Google")

**AcciÃ³n**:
1. Si > 50% eventos sin imagen: PAUSAR
2. Informar al usuario
3. Ofrecer:
   - Aumentar pausa entre requests (2s â†’ 4s)
   - Dividir en lotes mÃ¡s pequeÃ±os
   - Continuar mÃ¡s tarde

### Error: MySQL connection failed

**SÃ­ntoma**: Script de import no puede conectar a base de datos

**AcciÃ³n**:
1. Verificar que MySQL estÃ¡ corriendo
2. Verificar credenciales en `import_generic.py`
3. Ofrecer al usuario ejecutar manualmente o corregir config

### Error: JSON invÃ¡lido de Gemini

**SÃ­ntoma**: Gemini no responde en formato JSON o tiene errores de sintaxis

**AcciÃ³n**:
1. Intentar parsear y corregir automÃ¡ticamente (comillas, comas)
2. Si no se puede: pedir al usuario que repita el prompt en Gemini
3. Sugerir usar "Responde SOLO en JSON, sin texto adicional"

---

## ðŸ“ CHECKLIST PARA EL AGENTE

Usar esto para cada sesiÃ³n de scraping:

### Pre-Scraping
- [ ] Lista de ciudades recibida
- [ ] Determinar regiÃ³n de cada ciudad (Europa/LatinoamÃ©rica/NorteamÃ©rica)
- [ ] Verificar estructura de carpetas existe
- [ ] Crear carpetas necesarias
- [ ] Estimar nÃºmero de ciudades (Â¿cabe en lÃ­mite de Gemini?)

### Durante Scraping (por cada ciudad)
- [ ] Proporcionar prompt especÃ­fico para la ciudad
- [ ] Esperar respuesta de Gemini del usuario
- [ ] Crear archivo JSON en ruta correcta
- [ ] Validar JSON (sintaxis)
- [ ] Validar contenido (mÃ­nimo 10 eventos, campos obligatorios)
- [ ] Incrementar contador de sesiÃ³n (mÃ¡x 8)

### Post-Scraping
- [ ] Ejecutar script de imÃ¡genes
- [ ] Verificar % de eventos con imagen (>70%)
- [ ] Ejecutar script de import MySQL
- [ ] Verificar eventos insertados en DB
- [ ] Generar reporte completo
- [ ] Actualizar documentaciÃ³n de progreso
- [ ] Informar al usuario

### En Caso de Error
- [ ] Identificar tipo de error
- [ ] Aplicar soluciÃ³n correspondiente
- [ ] Informar al usuario claramente
- [ ] Ofrecer alternativas o prÃ³ximos pasos

---

## ðŸŽ¯ OBJETIVO FINAL

Al completar este protocolo, el resultado debe ser:

âœ… Eventos de todas las ciudades solicitadas en MySQL
âœ… MÃ­nimo 70% de eventos con imÃ¡genes reales
âœ… DetecciÃ³n automÃ¡tica de duplicados
âœ… Reporte claro de resultados
âœ… DocumentaciÃ³n actualizada
âœ… Usuario satisfecho con el proceso

---

**Ãšltima actualizaciÃ³n**: 2025-11-12
**VersiÃ³n**: 1.0
**Para**: Agentes de IA ejecutando scraping de eventos
