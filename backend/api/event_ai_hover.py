"""
Endpoint de IA para an√°lisis r√°pido de eventos con hover
Usa Gemini para dar contexto inteligente sobre cada evento
CON SISTEMA DE PRIORIDADES Y STREAMING
"""

from fastapi import APIRouter, HTTPException, Query
from fastapi.responses import StreamingResponse
from typing import Dict, Any
import os
import google.generativeai as genai
import logging
import json
import asyncio

router = APIRouter(prefix="/api/ai", tags=["ai-hover"])
logger = logging.getLogger(__name__)

# Configurar Gemini
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "")
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
    model = genai.GenerativeModel('gemini-2.5-flash')
else:
    model = None

# Sem√°foro para limitar requests concurrentes a Gemini
_gemini_semaphore = asyncio.Semaphore(3)  # Max 3 requests concurrentes

# üíæ Cach√© en memoria para insights (evitar llamadas repetidas a Gemini)
_insights_cache = {}

@router.post("/event-insight")
async def get_event_insight(event_data: Dict[str, Any]):
    """
    Obtiene insights r√°pidos de IA para un evento al hacer hover
    """
    if not model:
        return {
            "success": False,
            "error": "Gemini no configurado",
            "fallback": generate_fallback_insight(event_data)
        }

    try:
        title = event_data.get("title", "")
        venue = event_data.get("venue_name", "")
        category = event_data.get("category", "")
        location = event_data.get("location", "Buenos Aires")

        # üíæ Crear cache key
        cache_key = f"{title}:{venue}:{category}"

        # ‚úÖ Revisar cach√© primero
        if cache_key in _insights_cache:
            logger.info(f"‚úÖ Insight CACHEADO para: {title[:40]}...")
            return _insights_cache[cache_key]

        logger.info(f"üé≠ Generando insight NUEVO con Gemini para: {title[:40]}...")
        
        # ‚ö° Prompt ULTRA CONCISO para respuesta r√°pida
        prompt = f"""Evento: {title} | Lugar: {venue} | Categor√≠a: {category}

JSON con info √∫til (SIN texto adicional):
{{
  "quick_insight": "Qu√© esperar (1 l√≠nea)",
  "artist_info": "Info del artista/tema (1 l√≠nea)",
  "venue_tip": "Tip del lugar (1 l√≠nea)",
  "transport": "C√≥mo llegar",
  "nearby": "Qu√© hacer cerca",
  "vibe": "Ambiente (3 palabras)",
  "pro_tip": "Consejo √∫til"
}}"""

        # ‚ö° Configuraci√≥n para respuesta R√ÅPIDA y concisa
        generation_config = {
            'temperature': 0.7,
            'top_p': 0.95,
            'top_k': 40,
            'max_output_tokens': 400,  # Limitar a ~400 tokens = respuesta m√°s r√°pida
        }

        # ‚ö° Usar versi√≥n as√≠ncrona para no bloquear el servidor
        import asyncio
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(
            None,
            lambda: model.generate_content(
                prompt,
                generation_config=generation_config
            )
        )
        
        # Intentar parsear el JSON de la respuesta
        try:
            # Limpiar la respuesta de posibles caracteres extra
            json_str = response.text.strip()
            if json_str.startswith("```json"):
                json_str = json_str[7:]
            if json_str.startswith("```"):
                json_str = json_str[3:]
            if json_str.endswith("```"):
                json_str = json_str[:-3]
            
            insight_data = json.loads(json_str.strip())
        except json.JSONDecodeError:
            # Si no puede parsear, usar respuesta como texto
            insight_data = {
                "quick_insight": response.text[:100],
                "transport": "60, 152, 29",
                "vibe": "Copado y divertido",
                "best_for": "Todos los p√∫blicos"
            }
        
        result = {
            "success": True,
            "event_id": event_data.get("id", "unknown"),
            "insight": insight_data,
            "powered_by": "Gemini AI"
        }

        # üíæ Guardar en cach√©
        _insights_cache[cache_key] = result
        return result

    except Exception as e:
        logger.error(f"Error getting Gemini insight: {e}")
        return {
            "success": False,
            "error": str(e),
            "fallback": generate_fallback_insight(event_data)
        }

def generate_fallback_insight(event: Dict[str, Any]) -> Dict[str, Any]:
    """
    Genera insights b√°sicos sin IA cuando Gemini no est√° disponible
    """
    category = event.get("category", "general")
    venue = event.get("venue_name", "")
    
    # Insights predefinidos por categor√≠a
    insights = {
        "music": {
            "quick_insight": "Show en vivo con buena ac√∫stica",
            "venue_tip": "Lleg√° temprano para estar cerca del escenario",
            "transport": "60, 152, 29, Subte L√≠nea B",
            "nearby": "Hay bares copados en la zona para el after",
            "vibe": "Energ√©tico, social, vibrante",
            "pro_tip": "El sonido es mejor en el medio del lugar",
            "best_for": "Amantes de la m√∫sica en vivo"
        },
        "theater": {
            "quick_insight": "Obra para disfrutar del arte esc√©nico",
            "venue_tip": "Las mejores butacas est√°n en el medio",
            "transport": "39, 68, 194, Subte L√≠nea A",
            "nearby": "Caf√©s hist√≥ricos para charlar post funci√≥n",
            "vibe": "Cultural, elegante, √≠ntimo",
            "pro_tip": "Lleg√° 15 min antes para ubicarte tranquilo",
            "best_for": "Quienes buscan propuestas culturales"
        },
        "sports": {
            "quick_insight": "Evento deportivo con mucha pasi√≥n",
            "venue_tip": "Las populares tienen m√°s ambiente",
            "transport": "33, 53, 109",
            "nearby": "Parrillas t√≠picas para comer antes",
            "vibe": "Pasional, familiar, emocionante",
            "pro_tip": "Compr√° comida afuera, adentro es caro",
            "best_for": "Familias y fan√°ticos del deporte"
        },
        "cultural": {
            "quick_insight": "Experiencia cultural enriquecedora",
            "venue_tip": "Tomate tiempo para recorrer todo",
            "transport": "10, 17, 59, 67",
            "nearby": "Librer√≠as y galer√≠as en la zona",
            "vibe": "Tranquilo, inspirador, educativo",
            "pro_tip": "Los mi√©rcoles suele haber descuentos",
            "best_for": "Curiosos y amantes del arte"
        }
    }
    
    # Obtener insight seg√∫n categor√≠a o usar default
    insight = insights.get(category, insights["cultural"])
    
    # Personalizar seg√∫n el venue si es conocido
    if "Luna Park" in venue:
        insight["transport"] = "2, 105, 126, 195"
        insight["nearby"] = "Puerto Madero para cenar"
    elif "Teatro Col√≥n" in venue:
        insight["transport"] = "Subte L√≠nea D, 29, 39, 152"
        insight["nearby"] = "Av. Corrientes llena de teatros y bares"
    elif "Quality" in venue or "C√≥rdoba" in venue:
        insight["transport"] = "L√≠neas A, B, C del trolley"
        insight["nearby"] = "Nueva C√≥rdoba tiene muchos bares"
    
    return insight

@router.get("/quick-hover/{event_id}")
async def quick_hover_info(event_id: str):
    """
    Endpoint simplificado para hover r√°pido
    """
    # Para demo, generamos info b√°sica
    return {
        "event_id": event_id,
        "hover_text": "üéØ Evento popular ‚Ä¢ üöå L√≠neas 60, 152 ‚Ä¢ üìç Zona segura",
        "mini_tips": [
            "Lleg√° 30 min antes",
            "Zona con buenos bares",
            "F√°cil acceso en transporte"
        ]
    }


@router.post("/event-insight-stream")
async def get_event_insight_stream(event_data: Dict[str, Any]):
    """
    üåä STREAMING VERSION - Insights aparecen progresivamente
    """
    async def event_stream():
        if not model:
            # Enviar fallback r√°pido
            fallback = generate_fallback_insight(event_data)
            yield f"data: {json.dumps({'type': 'complete', 'insight': fallback})}\n\n"
            return

        try:
            title = event_data.get("title", "")
            venue = event_data.get("venue_name", "")
            category = event_data.get("category", "")
            location = event_data.get("location", "Buenos Aires")

            # Enviar evento de inicio
            yield f"data: {json.dumps({'type': 'start', 'message': 'Analizando evento...'})}\n\n"
            await asyncio.sleep(0.1)

            # Prompt espec√≠fico
            prompt = f"""
            Evento: {title}
            Lugar: {venue}
            Categor√≠a: {category}
            Ciudad: {location}

            Dame informaci√≥n SUPER CONCISA y √öTIL sobre este evento.
            Si conoc√©s la banda/artista/lugar, contame algo interesante.

            FORMATO de respuesta (JSON):
            {{
                "quick_insight": "1 l√≠nea sobre qu√© esperar del evento",
                "artist_info": "Si es una banda/artista conocido, 1 dato copado",
                "venue_tip": "1 tip sobre el lugar (d√≥nde es mejor ubicarse, etc)",
                "transport": "Colectivos que llegan ah√≠ (n√∫meros)",
                "nearby": "1 lugar copado para ir antes/despu√©s",
                "vibe": "En 3 palabras el ambiente",
                "pro_tip": "1 consejo que solo un local sabr√≠a",
                "best_for": "Para qui√©n es ideal este evento"
            }}

            Si no conoc√©s algo espec√≠fico, invent√° algo coherente y √∫til basado en el tipo de evento.
            Respond√© SOLO el JSON, sin explicaciones adicionales.
            """

            # Generar con Gemini (streaming nativo)
            response = model.generate_content(prompt, stream=True)

            accumulated_text = ""
            for chunk in response:
                if chunk.text:
                    accumulated_text += chunk.text
                    # Enviar chunk
                    yield f"data: {json.dumps({'type': 'chunk', 'text': chunk.text})}\n\n"
                    await asyncio.sleep(0.02)  # 20ms delay para efecto typing

            # Parsear JSON final
            try:
                json_str = accumulated_text.strip()
                if json_str.startswith("```json"):
                    json_str = json_str[7:]
                if json_str.startswith("```"):
                    json_str = json_str[3:]
                if json_str.endswith("```"):
                    json_str = json_str[:-3]

                insight_data = json.loads(json_str.strip())
            except json.JSONDecodeError:
                insight_data = {
                    "quick_insight": accumulated_text[:100] if accumulated_text else "Evento interesante",
                    "transport": "Varias l√≠neas de colectivo",
                    "vibe": "Copado y divertido",
                    "best_for": "Todos los p√∫blicos"
                }

            # Enviar resultado final
            yield f"data: {json.dumps({'type': 'complete', 'insight': insight_data})}\n\n"

        except Exception as e:
            logger.error(f"Error en streaming: {e}")
            fallback = generate_fallback_insight(event_data)
            yield f"data: {json.dumps({'type': 'error', 'error': str(e), 'fallback': fallback})}\n\n"

    return StreamingResponse(
        event_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "X-Accel-Buffering": "no"
        }
    )