"""
Smart Recommendations API - Sistema de recomendaciones inteligentes
Usa Gemini para generar sugerencias cuando no hay resultados exactos
"""

from fastapi import APIRouter, HTTPException
from typing import Dict, Any, List, Optional
from pydantic import BaseModel
import google.generativeai as genai
import json
import os
import aiomysql
from datetime import datetime, timedelta
import asyncio

# Import cultural context
from ai.cultural_context import detect_user_type, get_cultural_prompt, localize_event_description

router = APIRouter()

# Configurar Gemini
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "")
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

class SmartRecommendationRequest(BaseModel):
    original_query: str
    found_events: List[Dict[str, Any]]
    user_context: Optional[Dict[str, Any]] = {}
    no_results: bool = False

class SmartRecommendationResponse(BaseModel):
    original_query: str
    analysis: str
    recommendations: List[Dict[str, Any]]
    alternative_suggestions: List[str]
    follow_up_questions: List[str]
    personalized_message: str

async def get_similar_events_from_db(category: str = None, keywords: List[str] = None) -> List[Dict]:
    """Obtener eventos similares de la base de datos"""
    from main_mysql import pool
    
    try:
        async with pool.acquire() as conn:
            async with conn.cursor(aiomysql.DictCursor) as cursor:
                # Query base
                base_query = """
                    SELECT 
                        id, title, description, start_datetime, end_datetime,
                        venue_name, venue_address, category, subcategory,
                        price, currency, is_free, image_url, event_url, source_api
                    FROM events 
                    WHERE start_datetime >= NOW()
                """
                
                params = []
                conditions = []
                
                if category:
                    conditions.append("category = %s")
                    params.append(category)
                
                if keywords:
                    keyword_conditions = []
                    for keyword in keywords:
                        keyword_conditions.append("(title LIKE %s OR description LIKE %s)")
                        params.extend([f"%{keyword}%", f"%{keyword}%"])
                    
                    if keyword_conditions:
                        conditions.append(f"({' OR '.join(keyword_conditions)})")
                
                if conditions:
                    base_query += " AND " + " AND ".join(conditions)
                
                base_query += " ORDER BY start_datetime ASC LIMIT 20"
                
                await cursor.execute(base_query, params)
                events = await cursor.fetchall()
                return [dict(event) for event in events]
                
    except Exception as e:
        print(f"Error getting similar events: {e}")
        return []

def create_smart_recommendation_prompt(
    original_query: str, 
    found_events: List[Dict], 
    similar_events: List[Dict],
    user_context: Dict = None
) -> str:
    """Crear prompt culturalmente apropiado para recomendaciones inteligentes"""
    
    current_date = datetime.now().strftime("%Y-%m-%d %H:%M")
    user_location = user_context.get('location', 'Buenos Aires') if user_context else 'Buenos Aires'
    
    # 游 DETECCI칍N CULTURAL INTELIGENTE
    cultural_context = detect_user_type(
        query=original_query,
        location_context=user_context or {}
    )
    
    # 游꿢 PROMPT CULTURALMENTE APROPIADO
    cultural_prompt = get_cultural_prompt(cultural_context, original_query)
    
    # 游깵 EVENTOS LOCALIZADOS
    localized_found_events = [
        localize_event_description(event, cultural_context) 
        for event in found_events[:10]
    ]
    localized_similar_events = [
        localize_event_description(event, cultural_context) 
        for event in similar_events[:10]  
    ]
    
    # 游 PROMPT FINAL INTEGRADO
    prompt = f"""
{cultural_prompt}

DATOS PARA PROCESAR:
EVENTOS ENCONTRADOS ({len(found_events)}):
{json.dumps(localized_found_events, indent=2, default=str, ensure_ascii=False)}

EVENTOS SIMILARES DISPONIBLES ({len(similar_events)}):
{json.dumps(localized_similar_events, indent=2, default=str, ensure_ascii=False)}

CONTEXTO DETECTADO:
- Tipo de usuario: {cultural_context.user_type.value}
- Nivel cultural: {cultural_context.cultural_level.value}  
- Idioma: {cultural_context.detected_language}
- Confianza: {cultural_context.confidence:.2f}

TAREA ESPEC칈FICA:
1. **Analizar qu칠 busca** seg칰n su perfil cultural
2. **Recomendar eventos** en su estilo de comunicaci칩n
3. **Dar contexto cultural** apropiado para su nivel
4. **Sugerir plan completo** considerando horarios/costumbres locales

RESPONDE EN FORMATO JSON:
{{
    "analysis": "An치lisis de qu칠 busca (en su estilo de comunicaci칩n)",
    "main_recommendations": [
        {{
            "event_id": "id del evento",
            "title": "t칤tulo localizado",
            "reason": "por qu칠 lo recomiendas (estilo apropiado)",
            "match_score": "1-10", 
            "perfect_for": "tipo de persona/momento",
            "cultural_context": "explicaci칩n cultural si es turista"
        }}
    ],
    "alternative_suggestions": [
        "Sugerencias en el estilo de comunicaci칩n detectado",
        "Con jerga local si es local, con explicaciones si es turista"
    ],
    "follow_up_questions": [
        "Preguntas en el estilo apropiado"
    ],
    "personalized_message": "Mensaje personal en el tono/estilo correcto",
    "local_insights": [
        "Tips culturales apropiados para el nivel del usuario"
    ]
}}

IMPORTANTE: Us치 el estilo de comunicaci칩n detectado - jerga local para locales, explicativo para turistas.
Responde SOLO en JSON v치lido, sin markdown.
"""
    
    return prompt

@router.post("/recommend", response_model=SmartRecommendationResponse)
async def get_smart_recommendations(request: SmartRecommendationRequest):
    """
    Generar recomendaciones inteligentes basadas en b칰squeda original
    
    Casos de uso:
    1. Usuario busca algo espec칤fico pero no hay resultados exactos
    2. Usuario encuentra algo pero queremos sugerir experiencias complementarias
    3. Usuario parece indeciso y necesita orientaci칩n
    """
    
    if not GEMINI_API_KEY:
        raise HTTPException(
            status_code=503, 
            detail="Servicio de recomendaciones no disponible"
        )
    
    try:
        # 1. Analizar la consulta para extraer categor칤as e intenciones
        analysis_keywords = []
        detected_category = None
        
        query_lower = request.original_query.lower()
        
        # Detectar categor칤as
        if any(word in query_lower for word in ['teatro', 'obra', 'comedia', 'drama']):
            detected_category = 'theater'
            analysis_keywords.extend(['teatro', 'comedia', 'drama', 'espect치culo'])
            
        elif any(word in query_lower for word in ['concierto', 'm칰sica', 'banda', 'recital']):
            detected_category = 'music'
            analysis_keywords.extend(['m칰sica', 'concierto', 'show', 'recital'])
            
        elif any(word in query_lower for word in ['fiesta', 'party', 'boliche', 'after']):
            detected_category = 'party'
            analysis_keywords.extend(['fiesta', 'party', 'diversi칩n', 'noche'])
            
        elif any(word in query_lower for word in ['deporte', 'f칰tbol', 'partido', 'estadio']):
            detected_category = 'sports'
            analysis_keywords.extend(['deporte', 'f칰tbol', 'partido', 'estadio'])
        
        # 2. Buscar eventos similares si no hay resultados o para complementar
        similar_events = []
        if request.no_results or len(request.found_events) < 3:
            similar_events = await get_similar_events_from_db(
                category=detected_category,
                keywords=analysis_keywords[:3]  # Limitar keywords
            )
        
        # 3. Crear prompt para Gemini
        prompt = create_smart_recommendation_prompt(
            request.original_query,
            request.found_events,
            similar_events,
            request.user_context
        )
        
        # 4. Consultar Gemini
        model = genai.GenerativeModel('gemini-2.5-flash')
        response = await asyncio.create_task(
            asyncio.to_thread(model.generate_content, prompt)
        )
        
        # 5. Procesar respuesta
        try:
            ai_response = json.loads(response.text)
        except json.JSONDecodeError:
            # Fallback response si Gemini no devuelve JSON v치lido
            ai_response = {
                "analysis": f"An치lisis de b칰squeda: {request.original_query}",
                "main_recommendations": [],
                "alternative_suggestions": [
                    "Intent치 buscar con palabras similares",
                    "Explor치 otras categor칤as de eventos",
                    "Revis치 eventos en fechas cercanas"
                ],
                "follow_up_questions": [
                    "쯊e interesar칤a algo similar?",
                    "쯈uer칠s que te sugiera otras opciones?"
                ],
                "personalized_message": "No encontramos exactamente lo que busc치s, pero hay muchas otras opciones interesantes.",
                "local_insights": []
            }
        
        # 6. Construir respuesta final
        return SmartRecommendationResponse(
            original_query=request.original_query,
            analysis=ai_response.get('analysis', ''),
            recommendations=ai_response.get('main_recommendations', []),
            alternative_suggestions=ai_response.get('alternative_suggestions', []),
            follow_up_questions=ai_response.get('follow_up_questions', []),
            personalized_message=ai_response.get('personalized_message', '')
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=500, 
            detail=f"Error generando recomendaciones: {str(e)}"
        )

@router.post("/analyze-intent")
async def analyze_user_intent(request: Dict[str, Any]):
    """
    Analizar la intenci칩n del usuario para optimizar b칰squedas
    """
    
    query = request.get('query', '')
    context = request.get('context', {})
    
    if not GEMINI_API_KEY:
        return {"intent": "general_search", "confidence": 0.5}
    
    try:
        prompt = f"""
        Analiza esta consulta de usuario sobre eventos y detecta su intenci칩n:
        
        CONSULTA: "{query}"
        CONTEXTO: {json.dumps(context, default=str)}
        
        Responde en JSON con:
        {{
            "intent": "search_events|ask_recommendation|compare_options|plan_evening|find_venue",
            "confidence": 0.0-1.0,
            "extracted_filters": {{
                "category": "music|theater|sports|party|cultural|general",
                "date_preference": "today|tomorrow|weekend|next_week|flexible",
                "price_preference": "free|cheap|medium|expensive|any",
                "group_size": "solo|couple|friends|family|large_group",
                "mood": "energetic|relaxed|romantic|adventurous|cultural"
            }},
            "suggested_search_strategy": "exact_match|broad_search|alternative_suggestions|guided_discovery"
        }}
        """
        
        model = genai.GenerativeModel('gemini-2.5-flash')
        response = await asyncio.create_task(
            asyncio.to_thread(model.generate_content, prompt)
        )
        
        try:
            result = json.loads(response.text)
            return result
        except:
            return {"intent": "general_search", "confidence": 0.5}
            
    except Exception as e:
        return {"intent": "general_search", "confidence": 0.1, "error": str(e)}