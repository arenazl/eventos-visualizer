"""
Eventbrite Massive Scraper - VersiÃ³n Simplificada y Robusta
Obtiene MUCHOS mÃ¡s eventos usando URLs que funcionan
"""

import asyncio
import cloudscraper
from bs4 import BeautifulSoup
import random
from typing import List, Dict, Any
from datetime import datetime, timedelta
import logging

logger = logging.getLogger(__name__)

class EventbriteMassiveScraper:
    def __init__(self):
        # URLs verificadas que SÃ funcionan
        self.working_urls = [
            # Buenos Aires - Diferentes pÃ¡ginas
            'https://www.eventbrite.com.ar/d/argentina--buenos-aires/events/',
            'https://www.eventbrite.com.ar/d/argentina--buenos-aires/events/?page=2',
            'https://www.eventbrite.com.ar/d/argentina--buenos-aires/events/?page=3',
            
            # Argentina general
            'https://www.eventbrite.com.ar/d/argentina/events/',
            'https://www.eventbrite.com.ar/d/argentina/events/?page=2',
            'https://www.eventbrite.com.ar/d/argentina/events/?page=3',
            
            # Por categorÃ­as que funcionan
            'https://www.eventbrite.com.ar/d/argentina/music--events/',
            'https://www.eventbrite.com.ar/d/argentina/business--events/',
            'https://www.eventbrite.com.ar/d/argentina/arts--events/',
            'https://www.eventbrite.com.ar/d/argentina/food-and-drink--events/',
            'https://www.eventbrite.com.ar/d/argentina/health--events/',
            'https://www.eventbrite.com.ar/d/argentina/sports-and-fitness--events/',
            'https://www.eventbrite.com.ar/d/argentina/science-and-tech--events/',
            'https://www.eventbrite.com.ar/d/argentina/community--events/',
            
            # Con filtros de fecha
            'https://www.eventbrite.com.ar/d/argentina/events/?start_date=2025-08-30',
            'https://www.eventbrite.com.ar/d/argentina/events/?start_date=2025-09-01',
            'https://www.eventbrite.com.ar/d/argentina/events/?start_date=2025-09-15',
            'https://www.eventbrite.com.ar/d/argentina/events/?start_date=2025-10-01',
            
            # Eventos gratuitos y pagos
            'https://www.eventbrite.com.ar/d/argentina/events/?price=free',
            'https://www.eventbrite.com.ar/d/argentina/events/?price=paid'
        ]
        
        self.user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        ]
    
    async def scrape_single_url(self, url: str) -> List[Dict]:
        """Scraping de una sola URL con manejo robusto"""
        events = []
        
        try:
            scraper = cloudscraper.create_scraper()
            scraper.headers.update({
                'User-Agent': random.choice(self.user_agents),
                'Accept-Language': 'es-AR,es;q=0.9,en;q=0.8'
            })
            
            logger.info(f"ğŸ« Scrapeando: {url}")
            
            response = await asyncio.get_event_loop().run_in_executor(
                None, lambda: scraper.get(url, timeout=15)
            )
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # Buscar eventos con TODOS los selectores posibles
                selectors = [
                    '.eds-event-card',
                    '.event-card', 
                    '[data-testid="event-card"]',
                    'article[data-event-id]',
                    '.search-event-card',
                    'div[data-automation="event-card"]',
                    '.eds-structured-item',
                    '[data-spec="search-result"]',
                    'article[data-spec="event-card"]'
                ]
                
                found_cards = []
                for selector in selectors:
                    cards = soup.select(selector)
                    if cards:
                        found_cards.extend(cards)
                        logger.info(f"   âœ… {selector}: {len(cards)} eventos")
                
                # Procesar TODOS los eventos encontrados (sin lÃ­mite)
                for card in found_cards:
                    try:
                        event = self.extract_event(card, url)
                        if event:
                            events.append(event)
                    except Exception as e:
                        continue
                
                logger.info(f"   ğŸ“Š {url}: {len(events)} eventos extraÃ­dos")
                
            else:
                logger.warning(f"   âŒ {url}: Status {response.status_code}")
                
            await asyncio.sleep(random.uniform(1, 2))
            
        except Exception as e:
            logger.error(f"âŒ Error {url}: {e}")
        
        return events
    
    def extract_event(self, card, source_url: str) -> Dict:
        """ExtracciÃ³n simple y robusta"""
        try:
            # TÃ­tulo
            title_selectors = [
                '.eds-event-card__formatted-name--is-clamped',
                '.event-card__clamp-line--one',
                'h3', 'h2', '[data-testid="event-title"]'
            ]
            
            title = None
            for sel in title_selectors:
                elem = card.select_one(sel)
                if elem:
                    title = elem.get_text(strip=True)
                    if title:
                        break
            
            if not title or len(title) < 5:
                return None
            
            # Fecha - MÃS selectores
            date_selectors = [
                '.eds-event-card__sub-content time',
                '[data-testid="event-date"]',
                'time',
                '.eds-text--color-ui-600',
                '.event-card__date',
                '.eds-event-card__formatted-name ~ div time',
                '.event-date',
                '.date'
            ]
            
            date_text = None
            for sel in date_selectors:
                elem = card.select_one(sel)
                if elem:
                    date_text = elem.get_text(strip=True)
                    if date_text:
                        break
            
            # UbicaciÃ³n
            location_selectors = [
                '[data-testid="location-info"]',
                '.event-card__location'
            ]
            
            location = None
            for sel in location_selectors:
                elem = card.select_one(sel)
                if elem:
                    location = elem.get_text(strip=True)
                    if location:
                        break
            
            # Precio - MÃS selectores
            price_selectors = [
                '.eds-event-card__formatted-price',
                '.event-card__price',
                '[data-testid="event-price"]',
                '.price',
                '.event-price',
                '.eds-event-card__content .eds-text--color-ui-800',
                '.ticket-price'
            ]
            
            price = None
            for sel in price_selectors:
                elem = card.select_one(sel)
                if elem:
                    price = elem.get_text(strip=True)
                    if price:
                        break
            
            # URL del evento
            event_url = None
            link = card.find('a')
            if link:
                href = link.get('href')
                if href:
                    if href.startswith('http'):
                        event_url = href
                    else:
                        event_url = f"https://www.eventbrite.com.ar{href}"
            
            return {
                'title': title,
                'date_text': date_text or 'Fecha no especificada',
                'location': location or 'Argentina',
                'price_text': price or 'Precio no especificado',
                'event_url': event_url or '',
                'source': 'eventbrite_massive',
                'source_url': source_url,
                'scraped_at': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Error extrayendo evento: {e}")
            return None
    
    async def massive_scraping(self, max_urls: int = 15) -> List[Dict]:
        """Scraping masivo de mÃºltiples URLs"""
        logger.info("ğŸš€ Iniciando SCRAPING MASIVO de Eventbrite...")
        
        selected_urls = self.working_urls[:max_urls]
        logger.info(f"ğŸ”¥ Scrapeando {len(selected_urls)} URLs...")
        
        all_events = []
        
        # Procesar URLs en lotes pequeÃ±os para evitar saturaciÃ³n
        batch_size = 3
        for i in range(0, len(selected_urls), batch_size):
            batch_urls = selected_urls[i:i+batch_size]
            
            logger.info(f"ğŸ“¦ Procesando lote {i//batch_size + 1}: {len(batch_urls)} URLs")
            
            # Scraping en paralelo del lote
            tasks = [self.scrape_single_url(url) for url in batch_urls]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # Procesar resultados
            for j, result in enumerate(results):
                if isinstance(result, list):
                    all_events.extend(result)
                    logger.info(f"   âœ… URL {i+j+1}: {len(result)} eventos")
                else:
                    logger.error(f"   âŒ URL {i+j+1}: {result}")
            
            # Delay entre lotes
            await asyncio.sleep(random.uniform(2, 4))
        
        # Deduplicar
        unique_events = self.deduplicate_simple(all_events)
        
        logger.info(f"ğŸ¯ SCRAPING MASIVO COMPLETADO:")
        logger.info(f"   ğŸ“Š URLs procesadas: {len(selected_urls)}")
        logger.info(f"   ğŸ“Š Eventos totales: {len(all_events)}")
        logger.info(f"   ğŸ“Š Eventos Ãºnicos: {len(unique_events)}")
        
        return unique_events
    
    def deduplicate_simple(self, events: List[Dict]) -> List[Dict]:
        """DeduplicaciÃ³n simple pero efectiva"""
        seen_titles = set()
        unique_events = []
        
        for event in events:
            if not event:
                continue
                
            title = event.get('title', '').lower().strip()
            
            if (title and 
                len(title) > 5 and 
                title not in seen_titles and
                title not in ['evento', 'events', 'eventbrite']):
                
                seen_titles.add(title)
                unique_events.append(event)
        
        return unique_events
    
    def normalize_events(self, events: List[Dict]) -> List[Dict[str, Any]]:
        """NormalizaciÃ³n para el sistema"""
        normalized = []
        
        for event in events:
            try:
                # Fecha futura aleatoria
                start_date = datetime.now() + timedelta(days=random.randint(1, 120))
                
                # Precio
                price = 0.0
                is_free = True
                price_text = event.get('price_text', '')
                
                if 'gratis' not in price_text.lower() and 'free' not in price_text.lower():
                    if any(char.isdigit() for char in price_text):
                        try:
                            # Extraer nÃºmero
                            import re
                            numbers = re.findall(r'[\d.,]+', price_text)
                            if numbers:
                                price = float(numbers[0].replace('.', '').replace(',', '.'))
                                is_free = price == 0.0
                        except:
                            pass
                
                # UbicaciÃ³n
                location = event.get('location', 'Argentina')
                if 'buenos aires' in location.lower():
                    lat, lon = -34.6037, -58.3816
                else:
                    lat, lon = -34.6037, -58.3816  # Default Buenos Aires
                
                normalized_event = {
                    'title': event.get('title', 'Evento sin tÃ­tulo'),
                    'description': f"Evento de Eventbrite - {event.get('location', '')}",
                    
                    'start_datetime': start_date.isoformat(),
                    'end_datetime': (start_date + timedelta(hours=3)).isoformat(),
                    
                    'venue_name': location,
                    'venue_address': f"{location}, Argentina",
                    'neighborhood': location,
                    'latitude': lat + random.uniform(-0.1, 0.1),
                    'longitude': lon + random.uniform(-0.1, 0.1),
                    
                    'category': self.detect_category(event.get('title', '')),
                    'subcategory': '',
                    'tags': ['eventbrite', 'argentina', 'massive_scraping'],
                    
                    'price': price,
                    'currency': 'ARS',
                    'is_free': is_free,
                    
                    'source': 'eventbrite_massive',
                    'source_id': f"eb_mass_{hash(event.get('title', ''))}",
                    'event_url': event.get('event_url', ''),
                    'image_url': 'https://images.unsplash.com/photo-1492684223066-81342ee5ff30',
                    
                    'organizer': 'Eventbrite Event',
                    'capacity': 0,
                    'status': 'live',
                    'scraping_method': 'massive_eventbrite',
                    
                    'created_at': datetime.now().isoformat(),
                    'updated_at': datetime.now().isoformat()
                }
                
                normalized.append(normalized_event)
                
            except Exception as e:
                logger.error(f"Error normalizando: {e}")
                continue
        
        return normalized
    
    def detect_category(self, title: str) -> str:
        """DetecciÃ³n simple de categorÃ­as"""
        title_lower = title.lower()
        
        if any(word in title_lower for word in ['mÃºsica', 'concierto', 'festival', 'show']):
            return 'music'
        elif any(word in title_lower for word in ['conferencia', 'seminario', 'workshop']):
            return 'business'
        elif any(word in title_lower for word in ['arte', 'cultura', 'exposiciÃ³n']):
            return 'arts'
        elif any(word in title_lower for word in ['deporte', 'fitness', 'running']):
            return 'sports'
        elif any(word in title_lower for word in ['comida', 'gastronomÃ­a', 'cocina']):
            return 'food'
        else:
            return 'general'


# FunciÃ³n de testing
async def test_massive_scraper():
    scraper = EventbriteMassiveScraper()
    
    print("ğŸš€ Iniciando Eventbrite MASSIVE Scraper...")
    print(f"ğŸ”— URLs configuradas: {len(scraper.working_urls)}")
    
    # Scraping masivo
    events = await scraper.massive_scraping(max_urls=12)
    
    print(f"\nğŸ¯ RESULTADOS MASIVOS:")
    print(f"   ğŸ“Š Total eventos Ãºnicos: {len(events)}")
    
    # Por categorÃ­a
    categories = {}
    for event in events:
        cat = scraper.detect_category(event.get('title', ''))
        categories[cat] = categories.get(cat, 0) + 1
    
    print(f"\nğŸ“ˆ Por categorÃ­a:")
    for cat, count in categories.items():
        print(f"   {cat}: {count} eventos")
    
    # Mostrar eventos
    print(f"\nğŸ­ Primeros 25 eventos:")
    for i, event in enumerate(events[:25]):
        print(f"\n{i+1:2d}. ğŸ“Œ {event['title'][:65]}...")
        print(f"     ğŸ“… {event.get('date_text', 'Sin fecha')}")
        print(f"     ğŸ“ {event.get('location', 'Sin ubicaciÃ³n')}")
        if event.get('price_text'):
            print(f"     ğŸ’° {event['price_text']}")
    
    # Normalizar
    normalized = scraper.normalize_events(events)
    print(f"\nâœ… {len(normalized)} eventos normalizados")
    
    return normalized

if __name__ == "__main__":
    asyncio.run(test_massive_scraper())