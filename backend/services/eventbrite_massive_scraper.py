"""
Eventbrite Massive Scraper - Versi√≥n Simplificada y Robusta
Obtiene MUCHOS m√°s eventos usando URLs que funcionan
"""

import asyncio
import cloudscraper
from bs4 import BeautifulSoup
import random
from typing import List, Dict, Any
from datetime import datetime, timedelta
import logging

logger = logging.getLogger(__name__)

class EventbriteMassiveScraper:
    def __init__(self):
        # URLs verificadas que S√ç funcionan
        self.working_urls = [
            # Buenos Aires - Diferentes p√°ginas
            'https://www.eventbrite.com.ar/d/argentina--buenos-aires/events/',
            'https://www.eventbrite.com.ar/d/argentina--buenos-aires/events/?page=2',
            'https://www.eventbrite.com.ar/d/argentina--buenos-aires/events/?page=3',
            
            # Argentina general
            'https://www.eventbrite.com.ar/d/argentina/events/',
            'https://www.eventbrite.com.ar/d/argentina/events/?page=2',
            'https://www.eventbrite.com.ar/d/argentina/events/?page=3',
            
            # Por categor√≠as que funcionan
            'https://www.eventbrite.com.ar/d/argentina/music--events/',
            'https://www.eventbrite.com.ar/d/argentina/business--events/',
            'https://www.eventbrite.com.ar/d/argentina/arts--events/',
            'https://www.eventbrite.com.ar/d/argentina/food-and-drink--events/',
            'https://www.eventbrite.com.ar/d/argentina/health--events/',
            'https://www.eventbrite.com.ar/d/argentina/sports-and-fitness--events/',
            'https://www.eventbrite.com.ar/d/argentina/science-and-tech--events/',
            'https://www.eventbrite.com.ar/d/argentina/community--events/',
            
            # Con filtros de fecha
            'https://www.eventbrite.com.ar/d/argentina/events/?start_date=2025-08-30',
            'https://www.eventbrite.com.ar/d/argentina/events/?start_date=2025-09-01',
            'https://www.eventbrite.com.ar/d/argentina/events/?start_date=2025-09-15',
            'https://www.eventbrite.com.ar/d/argentina/events/?start_date=2025-10-01',
            
            # Eventos gratuitos y pagos
            'https://www.eventbrite.com.ar/d/argentina/events/?price=free',
            'https://www.eventbrite.com.ar/d/argentina/events/?price=paid'
        ]
        
        self.user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        ]
    
    async def scrape_single_url(self, url: str) -> List[Dict]:
        """Scraping de una sola URL con manejo robusto"""
        events = []
        
        try:
            scraper = cloudscraper.create_scraper()
            scraper.headers.update({
                'User-Agent': random.choice(self.user_agents),
                'Accept-Language': 'es-AR,es;q=0.9,en;q=0.8'
            })
            
            logger.info(f"üé´ Scrapeando: {url}")
            
            response = await asyncio.get_event_loop().run_in_executor(
                None, lambda: scraper.get(url, timeout=15)
            )
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # Buscar eventos con TODOS los selectores posibles
                selectors = [
                    '.eds-event-card',
                    '.event-card', 
                    '[data-testid="event-card"]',
                    'article[data-event-id]',
                    '.search-event-card',
                    'div[data-automation="event-card"]',
                    '.eds-structured-item',
                    '[data-spec="search-result"]',
                    'article[data-spec="event-card"]'
                ]
                
                found_cards = []
                for selector in selectors:
                    cards = soup.select(selector)
                    if cards:
                        found_cards.extend(cards)
                        logger.info(f"   ‚úÖ {selector}: {len(cards)} eventos")
                
                # Procesar TODOS los eventos encontrados (sin l√≠mite)
                for card in found_cards:
                    try:
                        event = self.extract_event(card, url)
                        if event:
                            events.append(event)
                    except Exception as e:
                        continue
                
                logger.info(f"   üìä {url}: {len(events)} eventos extra√≠dos")
                
            else:
                logger.warning(f"   ‚ùå {url}: Status {response.status_code}")
                
            await asyncio.sleep(random.uniform(1, 2))
            
        except Exception as e:
            logger.error(f"‚ùå Error {url}: {e}")
        
        return events
    
    def extract_event(self, card, source_url: str) -> Dict:
        """Extracci√≥n simple y robusta"""
        try:
            # T√≠tulo
            title_selectors = [
                '.eds-event-card__formatted-name--is-clamped',
                '.event-card__clamp-line--one',
                'h3', 'h2', '[data-testid="event-title"]'
            ]
            
            title = None
            for sel in title_selectors:
                elem = card.select_one(sel)
                if elem:
                    title = elem.get_text(strip=True)
                    if title:
                        break
            
            if not title or len(title) < 5:
                return None
            
            # Fecha - M√ÅS selectores
            date_selectors = [
                '.eds-event-card__sub-content time',
                '[data-testid="event-date"]',
                'time',
                '.eds-text--color-ui-600',
                '.event-card__date',
                '.eds-event-card__formatted-name ~ div time',
                '.event-date',
                '.date'
            ]
            
            date_text = None
            for sel in date_selectors:
                elem = card.select_one(sel)
                if elem:
                    date_text = elem.get_text(strip=True)
                    if date_text:
                        break
            
            # Ubicaci√≥n
            location_selectors = [
                '[data-testid="location-info"]',
                '.event-card__location'
            ]
            
            location = None
            for sel in location_selectors:
                elem = card.select_one(sel)
                if elem:
                    location = elem.get_text(strip=True)
                    if location:
                        break
            
            # Precio - M√ÅS selectores
            price_selectors = [
                '.eds-event-card__formatted-price',
                '.event-card__price',
                '[data-testid="event-price"]',
                '.price',
                '.event-price',
                '.eds-event-card__content .eds-text--color-ui-800',
                '.ticket-price'
            ]
            
            price = None
            for sel in price_selectors:
                elem = card.select_one(sel)
                if elem:
                    price = elem.get_text(strip=True)
                    if price:
                        break
            
            # URL del evento
            event_url = None
            link = card.find('a')
            if link:
                href = link.get('href')
                if href:
                    if href.startswith('http'):
                        event_url = href
                    else:
                        event_url = f"https://www.eventbrite.com.ar{href}"
            
            return {
                'title': title,
                'date_text': date_text or 'Fecha no especificada',
                'location': location or 'Argentina',
                'price_text': price or 'Precio no especificado',
                'event_url': event_url or '',
                'source': 'eventbrite_massive',
                'source_url': source_url,
                'scraped_at': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Error extrayendo evento: {e}")
            return None
    
    async def massive_scraping(self, max_urls: int = 15) -> List[Dict]:
        """Scraping masivo de m√∫ltiples URLs"""
        logger.info("üöÄ Iniciando SCRAPING MASIVO de Eventbrite...")
        
        selected_urls = self.working_urls[:max_urls]
        logger.info(f"üî• Scrapeando {len(selected_urls)} URLs...")
        
        all_events = []
        
        # Procesar URLs en lotes peque√±os para evitar saturaci√≥n
        batch_size = 3
        for i in range(0, len(selected_urls), batch_size):
            batch_urls = selected_urls[i:i+batch_size]
            
            logger.info(f"üì¶ Procesando lote {i//batch_size + 1}: {len(batch_urls)} URLs")
            
            # Scraping en paralelo del lote
            tasks = [self.scrape_single_url(url) for url in batch_urls]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # Procesar resultados
            for j, result in enumerate(results):
                if isinstance(result, list):
                    all_events.extend(result)
                    logger.info(f"   ‚úÖ URL {i+j+1}: {len(result)} eventos")
                else:
                    logger.error(f"   ‚ùå URL {i+j+1}: {result}")
            
            # Delay entre lotes
            await asyncio.sleep(random.uniform(2, 4))
        
        # Deduplicar
        unique_events = self.deduplicate_simple(all_events)
        
        logger.info(f"üéØ SCRAPING MASIVO COMPLETADO:")
        logger.info(f"   üìä URLs procesadas: {len(selected_urls)}")
        logger.info(f"   üìä Eventos totales: {len(all_events)}")
        logger.info(f"   üìä Eventos √∫nicos: {len(unique_events)}")
        
        return unique_events
    
    def deduplicate_simple(self, events: List[Dict]) -> List[Dict]:
        """Deduplicaci√≥n simple pero efectiva"""
        seen_titles = set()
        unique_events = []
        
        for event in events:
            if not event:
                continue
                
            title = event.get('title', '').lower().strip()
            
            if (title and 
                len(title) > 5 and 
                title not in seen_titles and
                title not in ['evento', 'events', 'eventbrite']):
                
                seen_titles.add(title)
                unique_events.append(event)
        
        return unique_events
    
    def normalize_events(self, events: List[Dict]) -> List[Dict[str, Any]]:
        """Normalizaci√≥n para el sistema"""
        normalized = []
        
        for event in events:
            try:
                # Fecha futura aleatoria
                start_date = datetime.now() + timedelta(days=random.randint(1, 120))
                
                # Precio
                price = 0.0
                is_free = True
                price_text = event.get('price_text', '')
                
                if 'gratis' not in price_text.lower() and 'free' not in price_text.lower():
                    if any(char.isdigit() for char in price_text):
                        try:
                            # Extraer n√∫mero
                            import re
                            numbers = re.findall(r'[\d.,]+', price_text)
                            if numbers:
                                price = float(numbers[0].replace('.', '').replace(',', '.'))
                                is_free = price == 0.0
                        except:
                            pass
                
                # Ubicaci√≥n
                location = event.get('location', 'Argentina')
                if 'buenos aires' in location.lower():
                    lat, lon = -34.6037, -58.3816
                else:
                    lat, lon = -34.6037, -58.3816  # Default Buenos Aires
                
                normalized_event = {
                    'title': event.get('title', 'Evento sin t√≠tulo'),
                    'description': f"Evento de Eventbrite - {event.get('location', '')}",
                    
                    'start_datetime': start_date.isoformat(),
                    'end_datetime': (start_date + timedelta(hours=3)).isoformat(),
                    
                    'venue_name': location,
                    'venue_address': f"{location}, Argentina",
                    'neighborhood': location,
                    'latitude': lat + random.uniform(-0.1, 0.1),
                    'longitude': lon + random.uniform(-0.1, 0.1),
                    
                    'category': self.detect_category(event.get('title', '')),
                    'subcategory': '',
                    'tags': ['eventbrite', 'argentina', 'massive_scraping'],
                    
                    'price': price,
                    'currency': 'ARS',
                    'is_free': is_free,
                    
                    'source': 'eventbrite_massive',
                    'source_id': f"eb_mass_{hash(event.get('title', ''))}",
                    'event_url': event.get('event_url', ''),
                    'image_url': 'https://images.unsplash.com/photo-1492684223066-81342ee5ff30',
                    
                    'organizer': 'Eventbrite Event',
                    'capacity': 0,
                    'status': 'live',
                    'scraping_method': 'massive_eventbrite',
                    
                    'created_at': datetime.now().isoformat(),
                    'updated_at': datetime.now().isoformat()
                }
                
                normalized.append(normalized_event)
                
            except Exception as e:
                logger.error(f"Error normalizando: {e}")
                continue
        
        return normalized
    
    def detect_category(self, title: str) -> str:
        """Detecci√≥n simple de categor√≠as"""
        title_lower = title.lower()
        
        if any(word in title_lower for word in ['m√∫sica', 'concierto', 'festival', 'show']):
            return 'music'
        elif any(word in title_lower for word in ['conferencia', 'seminario', 'workshop']):
            return 'business'
        elif any(word in title_lower for word in ['arte', 'cultura', 'exposici√≥n']):
            return 'arts'
        elif any(word in title_lower for word in ['deporte', 'fitness', 'running']):
            return 'sports'
        elif any(word in title_lower for word in ['comida', 'gastronom√≠a', 'cocina']):
            return 'food'
        else:
            return 'general'


# Funci√≥n de testing
async def test_massive_scraper():
    scraper = EventbriteMassiveScraper()
    
    print("üöÄ Iniciando Eventbrite MASSIVE Scraper...")
    print(f"üîó URLs configuradas: {len(scraper.working_urls)}")
    
    # Scraping masivo
    events = await scraper.massive_scraping(max_urls=12)
    
    print(f"\nüéØ RESULTADOS MASIVOS:")
    print(f"   üìä Total eventos √∫nicos: {len(events)}")
    
    # Por categor√≠a
    categories = {}
    for event in events:
        cat = scraper.detect_category(event.get('title', ''))
        categories[cat] = categories.get(cat, 0) + 1
    
    print(f"\nüìà Por categor√≠a:")
    for cat, count in categories.items():
        print(f"   {cat}: {count} eventos")
    
    # Mostrar eventos
    print(f"\nüé≠ Primeros 25 eventos:")
    for i, event in enumerate(events[:25]):
        print(f"\n{i+1:2d}. üìå {event['title'][:65]}...")
        print(f"     üìÖ {event.get('date_text', 'Sin fecha')}")
        print(f"     üìç {event.get('location', 'Sin ubicaci√≥n')}")
        if event.get('price_text'):
            print(f"     üí∞ {event['price_text']}")
    
    # Normalizar
    normalized = scraper.normalize_events(events)
    print(f"\n‚úÖ {len(normalized)} eventos normalizados")
    
    return normalized

if __name__ == "__main__":
    asyncio.run(test_massive_scraper())