"""
ğŸ”Œ SCRAPER INTERFACES - Contratos para Scrapers
Interfaces y clases base para mantener consistencia en todos los scrapers
"""

from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional
from dataclasses import dataclass

@dataclass
class ScraperRequest:
    """ğŸ“ Estructura de request para scrapers"""
    location: str
    category: Optional[str] = None
    limit: int = 30
    
@dataclass  
class ScraperResult:
    """ğŸ“Š Estructura de respuesta de scrapers"""
    events: List[Dict[str, Any]]
    scraper_name: str
    execution_time: float
    status: str  # 'success', 'partial', 'failed'
    error_message: Optional[str] = None

@dataclass
class ScraperConfig:
    """âš™ï¸ ConfiguraciÃ³n para scrapers"""
    timeout: int = 10
    retry_attempts: int = 3
    use_cache: bool = True
    cache_ttl: int = 1800  # 30 minutos

class BaseGlobalScraper(ABC):
    """
    ğŸŒ CLASE BASE PARA SCRAPERS GLOBALES
    
    Define el contrato que deben cumplir todos los scrapers globales.
    Estos scrapers funcionan en cualquier ubicaciÃ³n del mundo.
    """
    
    # ğŸ¯ PROPERTY HABILITADO POR DEFECTO - CADA SCRAPER DEBE DEFINIR
    enabled_by_default: bool = True
    
    # ğŸŒ PROPERTY PARA BÃšSQUEDA DE CIUDADES CERCANAS - CADA SCRAPER DEBE DEFINIR
    nearby_cities: bool = True
    
    def __init__(self, url_discovery_service, config: ScraperConfig = None):
        """
        Constructor con dependency injection
        
        Args:
            url_discovery_service: Servicio inyectado para descobrir URLs
            config: ConfiguraciÃ³n especÃ­fica del scraper
        """
        self.url_discovery_service = url_discovery_service
        self.config = config or ScraperConfig()
        self.scraper_name = self.__class__.__name__.replace('Scraper', '').lower()
        self.context = {}  # Contexto para informaciÃ³n adicional como detected_country
        
        # ğŸ–¼ï¸ Inicializar servicio de imÃ¡genes
        self._image_service = None
    
    def set_context(self, context: Dict[str, Any]):
        """
        ğŸ”§ ESTABLECER CONTEXTO ADICIONAL
        
        Args:
            context: Diccionario con informaciÃ³n adicional como detected_country
        """
        self.context.update(context)
    
    def _get_image_service(self):
        """
        ğŸ–¼ï¸ Lazy loading del servicio de imÃ¡genes
        
        Returns:
            GlobalImageService: Instancia del servicio de imÃ¡genes
        """
        if self._image_service is None:
            try:
                from services.global_image_service import global_image_service
                self._image_service = global_image_service
            except ImportError:
                self._image_service = None
        return self._image_service
    
    def _improve_event_image(self, event: Dict[str, Any]) -> Dict[str, Any]:
        """
        ğŸ–¼ï¸ Mejora imagen de un evento individual SOLO SI NO TIENE BUENA IMAGEN
        
        Args:
            event: Evento a mejorar
            
        Returns:
            Dict[str, Any]: Evento con imagen mejorada si es necesario
        """
        try:
            image_service = self._get_image_service()
            if not image_service:
                return event
            
            current_image = event.get('image_url', '')
            
            # Solo mejorar si no tiene buena imagen
            if not image_service.is_good_image(current_image):
                better_image = image_service.get_event_image(
                    title=event.get('title', ''),
                    category=event.get('category', ''),
                    venue=event.get('venue_name', ''),
                    country=self.context.get('detected_country', '')
                )
                
                event['image_url'] = better_image
                event['image_improved'] = True
                # Log solo para debugging del scraper especÃ­fico
                # logger.debug(f"ğŸ–¼ï¸ {self.scraper_name}: Imagen mejorada para '{event.get('title', '')[:30]}...'")
            else:
                event['image_improved'] = False
                
        except Exception:
            # Fallar silenciosamente para no romper el scraping
            event['image_improved'] = False
            
        return event
    
    @abstractmethod
    async def scrape_events(
        self, 
        location: str, 
        category: Optional[str] = None,
        limit: int = 30
    ) -> List[Dict[str, Any]]:
        """
        ğŸ¯ MÃ‰TODO PRINCIPAL DE SCRAPING
        
        Args:
            location: UbicaciÃ³n de bÃºsqueda (ciudad, paÃ­s, etc.)
            category: CategorÃ­a opcional de eventos
            limit: NÃºmero mÃ¡ximo de eventos a retornar
            
        Returns:
            Lista de eventos en formato estÃ¡ndar
        """
        pass
    
    def _standardize_event(self, raw_event: Dict[str, Any]) -> Dict[str, Any]:
        """
        ğŸ“‹ ESTANDARIZACIÃ“N DE EVENTOS
        
        Convierte evento raw del scraper al formato estÃ¡ndar de la aplicaciÃ³n
        ğŸ–¼ï¸ Mejora automÃ¡ticamente imÃ¡genes si no tienen buena calidad
        """
        # Crear evento estandarizado
        standardized_event = {
            'title': raw_event.get('title', 'Sin tÃ­tulo'),
            'description': raw_event.get('description', 'Sin descripciÃ³n'),
            'event_url': raw_event.get('event_url', ''),
            'image_url': raw_event.get('image_url', ''),
            'venue_name': raw_event.get('venue_name', 'UbicaciÃ³n no especificada'),
            'venue_address': raw_event.get('venue_address'),
            'start_datetime': raw_event.get('start_datetime'),
            'end_datetime': raw_event.get('end_datetime'),
            'price': raw_event.get('price'),
            'is_free': raw_event.get('is_free', False),
            'source': f"{self.scraper_name}_scraper",
            'category': raw_event.get('category', 'Eventos'),
            'external_id': raw_event.get('external_id')
        }
        
        # ğŸ–¼ï¸ Mejorar imagen automÃ¡ticamente si es necesario
        standardized_event = self._improve_event_image(standardized_event)
        
        return standardized_event

class BaseRegionalScraper(ABC):
    """
    ğŸ›ï¸ CLASE BASE PARA SCRAPERS REGIONALES
    
    Para scrapers especÃ­ficos de paÃ­ses o regiones
    """
    
    def __init__(self, url_discovery_service, config: ScraperConfig = None):
        self.url_discovery_service = url_discovery_service
        self.config = config or ScraperConfig()
        self.scraper_name = self.__class__.__name__.replace('Scraper', '').lower()
    
    @abstractmethod
    async def scrape_events(
        self, 
        location: str, 
        category: Optional[str] = None,
        limit: int = 30
    ) -> List[Dict[str, Any]]:
        pass

class BaseLocalScraper(ABC):
    """
    ğŸ™ï¸ CLASE BASE PARA SCRAPERS LOCALES
    
    Para scrapers especÃ­ficos de ciudades
    """
    
    def __init__(self, url_discovery_service, config: ScraperConfig = None):
        self.url_discovery_service = url_discovery_service
        self.config = config or ScraperConfig()
        self.scraper_name = self.__class__.__name__.replace('Scraper', '').lower()
    
    @abstractmethod
    async def scrape_events(
        self, 
        location: str, 
        category: Optional[str] = None,
        limit: int = 30
    ) -> List[Dict[str, Any]]:
        pass