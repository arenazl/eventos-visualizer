"""
ü§ñ AI PROVIDERS - Sistema Multi-Provider con Fallback Autom√°tico
Soporta m√∫ltiples servicios de IA: Groq, Gemini, Perplexity, OpenRouter
"""

import os
import logging
import aiohttp
import json
from abc import ABC, abstractmethod
from typing import Optional, Dict, Any, List
from enum import Enum

logger = logging.getLogger(__name__)


class ProviderType(str, Enum):
    """Tipos de providers disponibles"""
    GROK = "grok"          # xAI Grok (Elon Musk)
    GROQ = "groq"          # Groq (inferencia r√°pida)
    GEMINI = "gemini"      # Google Gemini
    PERPLEXITY = "perplexity"  # Perplexity AI
    OPENROUTER = "openrouter"  # OpenRouter


class AIProvider(ABC):
    """
    üß† CLASE BASE ABSTRACTA PARA PROVIDERS DE IA

    Todos los providers deben implementar estos m√©todos
    """

    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key
        self.session: Optional[aiohttp.ClientSession] = None
        self.name = self.__class__.__name__

    async def _get_session(self) -> aiohttp.ClientSession:
        """Obtiene o crea sesi√≥n HTTP reutilizable con timeout de 15s"""
        if self.session is None or self.session.closed:
            connector = aiohttp.TCPConnector(limit=10, limit_per_host=5)
            # ‚è±Ô∏è TIMEOUT CR√çTICO: 15 segundos m√°ximo para evitar freezes
            timeout = aiohttp.ClientTimeout(total=15, connect=5)
            self.session = aiohttp.ClientSession(
                connector=connector,
                timeout=timeout
            )
            logger.debug(f"üîó Nueva sesi√≥n HTTP para {self.name} (timeout: 15s)")
        return self.session

    async def close(self):
        """Cierra la sesi√≥n HTTP"""
        if self.session and not self.session.closed:
            await self.session.close()
            logger.debug(f"üîå Sesi√≥n cerrada para {self.name}")

    @abstractmethod
    async def generate(self, prompt: str, temperature: float = 0.3) -> Optional[str]:
        """
        Genera respuesta usando el provider de IA

        Args:
            prompt: Texto del prompt
            temperature: Nivel de creatividad (0.0-1.0)

        Returns:
            Respuesta del modelo o None si falla
        """
        pass

    @abstractmethod
    def is_configured(self) -> bool:
        """Verifica si el provider est√° configurado con API key"""
        pass

    def __str__(self):
        return self.name


class GrokProvider(AIProvider):
    """
    üöÄ GROK PROVIDER - xAI de Elon Musk

    Caracter√≠sticas:
    - Modelo Grok-4-latest (muy potente)
    - API compatible con OpenAI
    - Buen razonamiento y contexto
    """

    def __init__(self, api_key: Optional[str] = None):
        super().__init__(api_key or os.getenv('GROK_API_KEY'))
        self.base_url = "https://api.x.ai/v1/chat/completions"
        self.model = "grok-3"  # Modelo actual (grok-beta fue deprecado 2025-09-15)

    def is_configured(self) -> bool:
        return bool(self.api_key)

    async def generate(self, prompt: str, temperature: float = 0.3) -> Optional[str]:
        """Genera respuesta usando Grok (xAI)"""
        try:
            if not self.api_key:
                logger.warning("‚ö†Ô∏è GROK_API_KEY no configurada")
                return None

            session = await self._get_session()

            payload = {
                "model": self.model,
                "messages": [
                    {"role": "user", "content": prompt}
                ],
                "temperature": temperature,
                "stream": False
            }

            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }

            async with session.post(self.base_url, json=payload, headers=headers) as response:
                if response.status == 200:
                    data = await response.json()
                    if 'choices' in data and len(data['choices']) > 0:
                        text = data['choices'][0]['message']['content']
                        logger.info(f"‚úÖ Grok respondi√≥ exitosamente")
                        return text.strip()
                    else:
                        logger.warning(f"‚ö†Ô∏è Grok response sin contenido: {data}")
                        return None
                else:
                    error_text = await response.text()
                    logger.error(f"‚ùå Grok API error: HTTP {response.status} - {error_text}")
                    return None

        except Exception as e:
            import traceback
            logger.error(f"‚ùå Error en Grok provider: {str(e)}")
            logger.error(f"‚ùå Traceback: {traceback.format_exc()}")
            return None


class GroqProvider(AIProvider):
    """
    ‚ö° GROQ PROVIDER - Ultra R√°pido

    Caracter√≠sticas:
    - 14,400 requests/d√≠a gratis
    - 500+ tokens/segundo
    - Modelos: Llama 3, Mixtral, Gemma
    """

    def __init__(self, api_key: Optional[str] = None):
        super().__init__(api_key or os.getenv('GROQ_API_KEY'))
        self.base_url = "https://api.groq.com/openai/v1/chat/completions"
        self.model = "llama-3.1-70b-versatile"  # Modelo actualizado

    def is_configured(self) -> bool:
        return bool(self.api_key)

    async def generate(self, prompt: str, temperature: float = 0.3) -> Optional[str]:
        """Genera respuesta usando Groq"""
        try:
            if not self.api_key:
                logger.warning("‚ö†Ô∏è GROQ_API_KEY no configurada")
                return None

            session = await self._get_session()

            payload = {
                "model": self.model,
                "messages": [
                    {"role": "user", "content": prompt}
                ],
                "temperature": temperature,
                "max_tokens": 8192
            }

            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }

            async with session.post(self.base_url, json=payload, headers=headers) as response:
                if response.status == 200:
                    data = await response.json()
                    if 'choices' in data and len(data['choices']) > 0:
                        text = data['choices'][0]['message']['content']
                        logger.info(f"‚úÖ Groq respondi√≥ exitosamente")
                        return text.strip()
                    else:
                        logger.warning(f"‚ö†Ô∏è Groq response sin contenido: {data}")
                        return None
                else:
                    error_text = await response.text()
                    logger.error(f"‚ùå Groq API error: HTTP {response.status} - {error_text}")
                    return None

        except Exception as e:
            logger.error(f"‚ùå Error en Groq provider: {e}")
            return None


class GeminiProvider(AIProvider):
    """
    üî∑ GEMINI PROVIDER - Google AI

    Caracter√≠sticas:
    - 250 requests/d√≠a gratis
    - Buen an√°lisis de contexto
    - Integraci√≥n con Google
    """

    def __init__(self, api_key: Optional[str] = None):
        super().__init__(api_key or os.getenv('GEMINI_API_KEY'))
        self.model = "gemini-2.5-flash"

    def is_configured(self) -> bool:
        return bool(self.api_key)

    async def generate(self, prompt: str, temperature: float = 0.3) -> Optional[str]:
        """Genera respuesta usando Gemini"""
        try:
            if not self.api_key:
                logger.warning("‚ö†Ô∏è GEMINI_API_KEY no configurada")
                return None

            session = await self._get_session()

            url = f"https://generativelanguage.googleapis.com/v1beta/models/{self.model}:generateContent?key={self.api_key}"

            payload = {
                "contents": [{
                    "parts": [{
                        "text": prompt
                    }]
                }],
                "generationConfig": {
                    "temperature": temperature,
                    "maxOutputTokens": 8192
                }
            }

            async with session.post(url, json=payload) as response:
                if response.status == 200:
                    data = await response.json()

                    if 'candidates' in data and len(data['candidates']) > 0:
                        candidate = data['candidates'][0]
                        if 'content' in candidate and 'parts' in candidate['content']:
                            if len(candidate['content']['parts']) > 0:
                                text = candidate['content']['parts'][0]['text']
                                logger.info(f"‚úÖ Gemini respondi√≥ exitosamente")
                                return text.strip()

                    logger.warning(f"‚ö†Ô∏è Gemini response sin contenido v√°lido")
                    return None
                else:
                    error_text = await response.text()
                    logger.error(f"‚ùå Gemini API error: HTTP {response.status} - {error_text}")
                    return None

        except Exception as e:
            logger.error(f"‚ùå Error en Gemini provider: {e}")
            return None


class PerplexityProvider(AIProvider):
    """
    üîç PERPLEXITY PROVIDER - B√∫squeda en Tiempo Real

    Caracter√≠sticas:
    - Acceso a web en tiempo real
    - Informaci√≥n actualizada
    - 5 requests/hora gratis
    """

    def __init__(self, api_key: Optional[str] = None):
        super().__init__(api_key or os.getenv('PERPLEXITY_API_KEY'))
        self.base_url = "https://api.perplexity.ai/chat/completions"
        self.model = "pplx-7b-online"  # Modelo con b√∫squeda web

    def is_configured(self) -> bool:
        return bool(self.api_key)

    async def generate(self, prompt: str, temperature: float = 0.3) -> Optional[str]:
        """Genera respuesta usando Perplexity con b√∫squeda web"""
        try:
            if not self.api_key:
                logger.warning("‚ö†Ô∏è PERPLEXITY_API_KEY no configurada")
                return None

            session = await self._get_session()

            payload = {
                "model": self.model,
                "messages": [
                    {"role": "user", "content": prompt}
                ],
                "temperature": temperature
            }

            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }

            async with session.post(self.base_url, json=payload, headers=headers) as response:
                if response.status == 200:
                    data = await response.json()
                    if 'choices' in data and len(data['choices']) > 0:
                        text = data['choices'][0]['message']['content']
                        logger.info(f"‚úÖ Perplexity respondi√≥ exitosamente")
                        return text.strip()
                    else:
                        logger.warning(f"‚ö†Ô∏è Perplexity response sin contenido")
                        return None
                else:
                    error_text = await response.text()
                    logger.error(f"‚ùå Perplexity API error: HTTP {response.status} - {error_text}")
                    return None

        except Exception as e:
            logger.error(f"‚ùå Error en Perplexity provider: {e}")
            return None


class OpenRouterProvider(AIProvider):
    """
    üîÑ OPENROUTER PROVIDER - M√∫ltiples Modelos

    Caracter√≠sticas:
    - Acceso a GPT-4, Claude, Gemini, Llama
    - Pricing transparente
    - Fallback autom√°tico entre modelos
    """

    def __init__(self, api_key: Optional[str] = None):
        super().__init__(api_key or os.getenv('OPENROUTER_API_KEY'))
        self.base_url = "https://openrouter.ai/api/v1/chat/completions"
        # Modelos ordenados por precio (m√°s barato primero)
        self.models = [
            "google/gemini-flash-1.5",
            "meta-llama/llama-3-70b",
            "anthropic/claude-3-haiku",
            "openai/gpt-4o-mini"
        ]
        self.current_model = self.models[0]

    def is_configured(self) -> bool:
        return bool(self.api_key)

    async def generate(self, prompt: str, temperature: float = 0.3) -> Optional[str]:
        """Genera respuesta usando OpenRouter con fallback"""
        try:
            if not self.api_key:
                logger.warning("‚ö†Ô∏è OPENROUTER_API_KEY no configurada")
                return None

            session = await self._get_session()

            # Intentar con cada modelo hasta que uno funcione
            for model in self.models:
                try:
                    payload = {
                        "model": model,
                        "messages": [
                            {"role": "user", "content": prompt}
                        ],
                        "temperature": temperature
                    }

                    headers = {
                        "Authorization": f"Bearer {self.api_key}",
                        "Content-Type": "application/json",
                        "HTTP-Referer": "https://eventos-visualizer.com",
                        "X-Title": "Eventos Visualizer"
                    }

                    async with session.post(self.base_url, json=payload, headers=headers) as response:
                        if response.status == 200:
                            data = await response.json()
                            if 'choices' in data and len(data['choices']) > 0:
                                text = data['choices'][0]['message']['content']
                                logger.info(f"‚úÖ OpenRouter ({model}) respondi√≥ exitosamente")
                                self.current_model = model
                                return text.strip()
                        else:
                            logger.warning(f"‚ö†Ô∏è OpenRouter modelo {model} fall√≥: HTTP {response.status}")
                            continue

                except Exception as model_error:
                    logger.warning(f"‚ö†Ô∏è Error con modelo {model}: {model_error}")
                    continue

            logger.error("‚ùå Todos los modelos de OpenRouter fallaron")
            return None

        except Exception as e:
            logger.error(f"‚ùå Error en OpenRouter provider: {e}")
            return None
