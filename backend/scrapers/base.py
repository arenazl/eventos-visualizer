"""
üéØ BASE SCRAPER INTERFACE
Interfaz que todos los scrapers deben implementar para garantizar consistencia
"""

from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional
from pydantic import BaseModel, Field
from datetime import datetime
from enum import Enum

class EventCategory(str, Enum):
    """Categor√≠as est√°ndar de eventos"""
    MUSIC = "music"
    SPORTS = "sports"
    ARTS = "arts"
    TECH = "tech"
    FOOD = "food"
    BUSINESS = "business"
    COMMUNITY = "community"
    FAMILY = "family"
    FILM = "film"
    HEALTH = "health"
    OTHER = "other"

class Event(BaseModel):
    """
    üìÖ MODELO EST√ÅNDAR DE EVENTO
    Todos los scrapers deben normalizar sus datos a este formato
    """
    # Campos b√°sicos (requeridos)
    title: str = Field(..., description="T√≠tulo del evento")
    source: str = Field(..., description="Fuente del evento (eventbrite, meetup, etc)")
    
    # Campos opcionales pero importantes
    description: Optional[str] = Field(None, description="Descripci√≥n completa del evento")
    
    # Fecha y hora
    start_date: Optional[datetime] = Field(None, description="Fecha/hora de inicio")
    end_date: Optional[datetime] = Field(None, description="Fecha/hora de fin")
    date_display: Optional[str] = Field(None, description="Fecha formateada para mostrar")
    
    # Ubicaci√≥n
    venue_name: Optional[str] = Field(None, description="Nombre del lugar")
    venue_address: Optional[str] = Field(None, description="Direcci√≥n completa")
    city: Optional[str] = Field(None, description="Ciudad")
    country: Optional[str] = Field(None, description="Pa√≠s")
    latitude: Optional[float] = Field(None, description="Latitud")
    longitude: Optional[float] = Field(None, description="Longitud")
    
    # Precio y tickets
    price: Optional[float] = Field(None, description="Precio del evento")
    price_display: Optional[str] = Field(None, description="Precio formateado (ej: '$50' o 'Gratis')")
    currency: str = Field("ARS", description="Moneda")
    is_free: bool = Field(False, description="Si el evento es gratuito")
    ticket_url: Optional[str] = Field(None, description="URL para comprar tickets")
    
    # Multimedia
    image_url: Optional[str] = Field(None, description="URL de imagen principal")
    thumbnail_url: Optional[str] = Field(None, description="URL de thumbnail")
    
    # Metadata
    source_url: Optional[str] = Field(None, description="URL original del evento")
    source_id: Optional[str] = Field(None, description="ID en el sistema origen")
    category: Optional[EventCategory] = Field(EventCategory.OTHER, description="Categor√≠a del evento")
    tags: List[str] = Field(default_factory=list, description="Tags/etiquetas del evento")
    
    # Informaci√≥n adicional
    organizer_name: Optional[str] = Field(None, description="Nombre del organizador")
    organizer_url: Optional[str] = Field(None, description="URL del organizador")
    attendee_count: Optional[int] = Field(None, description="N√∫mero de asistentes confirmados")
    capacity: Optional[int] = Field(None, description="Capacidad m√°xima")
    
    # Control
    scraped_at: datetime = Field(default_factory=datetime.now, description="Cu√°ndo se scrape√≥")
    
    class Config:
        json_encoders = {
            datetime: lambda v: v.isoformat() if v else None
        }

class ScraperStatus(str, Enum):
    """Estados posibles de un scraper"""
    SUCCESS = "success"
    ERROR = "error"
    TIMEOUT = "timeout"
    NO_RESULTS = "no_results"
    RATE_LIMITED = "rate_limited"

class ScraperResult(BaseModel):
    """
    üìä RESULTADO DE UN SCRAPER
    Wrapper para el resultado de cada scraper
    """
    scraper: str = Field(..., description="Nombre del scraper")
    status: ScraperStatus = Field(..., description="Estado de la ejecuci√≥n")
    events: List[Event] = Field(default_factory=list, description="Eventos encontrados")
    error: Optional[str] = Field(None, description="Mensaje de error si fall√≥")
    execution_time: float = Field(0.0, description="Tiempo de ejecuci√≥n en segundos")
    events_count: int = Field(0, description="Cantidad de eventos encontrados")
    
    def __init__(self, **data):
        super().__init__(**data)
        self.events_count = len(self.events)

class IScraper(ABC):
    """
    üîß INTERFAZ BASE PARA SCRAPERS
    Todos los scrapers deben heredar de esta clase e implementar sus m√©todos
    """
    
    # Configuraci√≥n b√°sica del scraper
    name: str = "base_scraper"
    timeout: int = 5  # Timeout en segundos
    enabled: bool = True
    priority: int = 10  # Prioridad de ejecuci√≥n (menor = m√°s prioritario)
    
    def __init__(self, api_key: Optional[str] = None):
        """
        Constructor base
        
        Args:
            api_key: API key si el scraper la necesita
        """
        self.api_key = api_key
    
    @abstractmethod
    async def scrape(self, location: str, limit: int = 10, **kwargs) -> Dict[str, Any]:
        """
        üéØ M√âTODO PRINCIPAL DE SCRAPING
        Debe ser implementado por cada scraper
        
        Args:
            location: Ubicaci√≥n para buscar eventos
            limit: Cantidad m√°xima de eventos a retornar
            **kwargs: Par√°metros adicionales espec√≠ficos del scraper
            
        Returns:
            Dict con los datos crudos del scraper
        """
        pass
    
    @abstractmethod
    def normalize_output(self, raw_data: Dict[str, Any]) -> List[Event]:
        """
        üîÑ NORMALIZACI√ìN DE DATOS
        Convierte los datos crudos del scraper al formato Event est√°ndar
        
        Args:
            raw_data: Datos crudos retornados por scrape()
            
        Returns:
            Lista de eventos normalizados
        """
        pass
    
    async def execute(self, location: str, limit: int = 10, **kwargs) -> ScraperResult:
        """
        ‚ö° EJECUCI√ìN COMPLETA
        Ejecuta el scraping y normalizaci√≥n, manejando errores
        
        Args:
            location: Ubicaci√≥n para buscar eventos
            limit: Cantidad m√°xima de eventos
            
        Returns:
            ScraperResult con eventos normalizados o error
        """
        import time
        start_time = time.time()
        
        try:
            # Ejecutar scraping
            raw_data = await self.scrape(location, limit, **kwargs)
            
            # Normalizar datos
            events = self.normalize_output(raw_data)
            
            execution_time = time.time() - start_time
            
            return ScraperResult(
                scraper=self.name,
                status=ScraperStatus.SUCCESS if events else ScraperStatus.NO_RESULTS,
                events=events,
                execution_time=execution_time
            )
            
        except asyncio.TimeoutError:
            return ScraperResult(
                scraper=self.name,
                status=ScraperStatus.TIMEOUT,
                error=f"Timeout despu√©s de {self.timeout} segundos",
                execution_time=time.time() - start_time
            )
            
        except Exception as e:
            return ScraperResult(
                scraper=self.name,
                status=ScraperStatus.ERROR,
                error=str(e),
                execution_time=time.time() - start_time
            )
    
    def parse_date(self, date_str: Optional[str]) -> Optional[datetime]:
        """
        üóìÔ∏è HELPER: Parser de fechas com√∫n
        """
        if not date_str:
            return None
            
        from dateutil import parser
        try:
            return parser.parse(date_str)
        except:
            return None
    
    def clean_price(self, price_str: Optional[str]) -> Optional[float]:
        """
        üí∞ HELPER: Limpieza de precios
        """
        if not price_str:
            return None
            
        import re
        # Remover s√≠mbolos de moneda y espacios
        clean = re.sub(r'[^\d.,]', '', str(price_str))
        clean = clean.replace(',', '.')
        
        try:
            return float(clean)
        except:
            return None
    
    def detect_category(self, text: str) -> EventCategory:
        """
        üè∑Ô∏è HELPER: Detecci√≥n autom√°tica de categor√≠a
        """
        text_lower = text.lower()
        
        # Keywords por categor√≠a
        categories = {
            EventCategory.MUSIC: ['concert', 'concierto', 'music', 'm√∫sica', 'band', 'banda', 'dj', 'festival'],
            EventCategory.SPORTS: ['sport', 'deporte', 'football', 'f√∫tbol', 'basketball', 'tennis', 'match', 'partido'],
            EventCategory.ARTS: ['art', 'arte', 'exhibition', 'exposici√≥n', 'gallery', 'galer√≠a', 'museum', 'museo'],
            EventCategory.TECH: ['tech', 'technology', 'tecnolog√≠a', 'programming', 'developer', 'startup', 'code'],
            EventCategory.FOOD: ['food', 'comida', 'restaurant', 'gastro', 'wine', 'vino', 'cooking', 'cocina'],
            EventCategory.BUSINESS: ['business', 'negocio', 'networking', 'conference', 'conferencia', 'workshop'],
            EventCategory.COMMUNITY: ['community', 'comunidad', 'meetup', 'social', 'volunteer', 'voluntario'],
            EventCategory.FAMILY: ['family', 'familia', 'kids', 'ni√±os', 'children', 'parents'],
            EventCategory.FILM: ['film', 'movie', 'pel√≠cula', 'cinema', 'cine', 'screening'],
            EventCategory.HEALTH: ['health', 'salud', 'wellness', 'bienestar', 'yoga', 'meditation', 'fitness']
        }
        
        for category, keywords in categories.items():
            if any(keyword in text_lower for keyword in keywords):
                return category
                
        return EventCategory.OTHER

import asyncio