# üìã PROCEDIMIENTO MANUAL DE SCRAPING - VALIDADO

**Fecha**: 2025-11-15
**Estado**: ‚úÖ PROCEDIMIENTO OFICIAL
**Validado con**: C√≥rdoba (18 eventos exitosos)

---

## üéØ ARQUITECTURA DE 4 FASES (ORDEN CR√çTICO)

### **FASE 1: SCRAPING CON PUPPETEER MCP**
**Input**: Ciudad (ej: "Rosario, Argentina")
**Output**: `backend/data/scrapper_results/raw/gemini/{ciudad}_YYYY-MM-DD.txt`
**Tiempo**: ~30 segundos

#### Pasos:
1. Abrir Puppeteer con Gemini:
```bash
mcp__puppeteer__puppeteer_navigate
url: https://gemini.google.com
```

2. Esperar carga completa (5 segundos)

3. Enviar prompt (copiar exacto):
```
me podr√≠as pasar por lo menos 20 eventos, fiestas, festivales, encuentros en {CIUDAD}, {PAIS} de hoy a fin de mes?, si puede ser que incluya su nombre, descripci√≥n, fecha, lugar, direcci√≥n, barrio, precio y alguna info extra que tengas!
```

4. Esperar respuesta de Gemini (20-30 segundos)

5. Extraer texto completo y guardarlo en:
   - `backend/data/scrapper_results/raw/gemini/{ciudad_lowercase}_2025-11-15.txt`

**Formato esperado de Gemini**: Tabla TSV con columnas separadas por TAB

---

### **FASE 2: PARSING CON REGEX**
**Input**: RAW .txt de FASE 1
**Output**: `backend/data/scrapper_results/parsed/gemini/{ciudad}_YYYY-MM-DD.json`
**Tiempo**: <1 segundo

#### Comando:
```bash
cd backend/data/final_guide/scripts
python fase2_parse.py
```

#### Verificar output:
```bash
cat backend/data/scrapper_results/parsed/gemini/{ciudad}_2025-11-15.json
```

**Debe contener**: Array de eventos con campos: nombre, descripcion, fecha, lugar, direccion, barrio, precio, ciudad, category, subcategory, es_gratis, source

---

### **FASE 3: ACTUALIZAR IM√ÅGENES** ‚≠ê CR√çTICO
**Input**: JSON de FASE 2
**Output**: JSON actualizado con `image_url` completo
**Tiempo**: ~5-10 segundos por evento

#### üö® **REGLA DE ORO**:
**"El usuario entra al evento M√ÅS por la imagen que por el t√≠tulo"**

#### Pasos:
1. Leer JSON de FASE 2
2. Para cada evento:
   - Buscar imagen con Google Images (3 etapas):
     1. T√≠tulo del evento
     2. Keywords de descripci√≥n
     3. Solo venue
   - Agregar `image_url` al JSON
3. Guardar JSON actualizado (mismo archivo)

#### Script (crear si no existe):
```bash
python backend/data/scripts/fase3_update_images.py --input parsed/gemini/{ciudad}_2025-11-15.json
```

**Importante**: Eventos SIN im√°genes = eventos incompletos = mala UX

---

### **FASE 4: IMPORT A MYSQL**
**Input**: JSON con im√°genes de FASE 3
**Output**: Eventos completos en MySQL
**Tiempo**: ~1 segundo

#### Comando:
```bash
cd backend/data/final_guide/scripts
python fase3_import.py
```

**Nota**: Este script deber√≠a renombrarse a `fase4_import.py` en el futuro

#### Verificaci√≥n:
- ‚úÖ Eventos insertados: Nuevos en DB
- ‚è≠Ô∏è Eventos duplicados: Ya exist√≠an (fuzzy 80%)
- ‚ùå Errores: Revisar logs

---

## üìä CHECKLIST POR CIUDAD

### ‚úÖ **C√≥rdoba** (COMPLETADO - PERO SIN IM√ÅGENES)
- [x] FASE 1: Scraping ‚Üí 18 eventos en RAW
- [x] FASE 2: Parsing ‚Üí 18 eventos en JSON
- [ ] **FASE 3: Im√°genes** ‚ö†Ô∏è SALTADO (ERROR)
- [x] FASE 4: Import ‚Üí 18 eventos en MySQL

**Estado**: ‚ö†Ô∏è Eventos en MySQL SIN im√°genes - necesita correcci√≥n retroactiva

---

### ‚è≥ **Rosario** (EN PROGRESO)
- [ ] FASE 1: Scraping ‚Üí RAW .txt
- [ ] FASE 2: Parsing ‚Üí JSON
- [ ] FASE 3: Im√°genes ‚Üí JSON completo
- [ ] FASE 4: Import ‚Üí MySQL

---

### ‚è∏Ô∏è **Buenos Aires** (PENDIENTE)
- [ ] FASE 1: Scraping ‚Üí RAW .txt
- [ ] FASE 2: Parsing ‚Üí JSON
- [ ] FASE 3: Im√°genes ‚Üí JSON completo
- [ ] FASE 4: Import ‚Üí MySQL

**Nota**: Buenos Aires tiene 10 barrios adicionales que tambi√©n deben procesarse

---

## üö® ERRORES COMUNES A EVITAR

### ‚ùå **ERROR 1: Importar sin im√°genes**
- **S√≠ntoma**: Eventos en MySQL con `image_url` vac√≠o
- **Causa**: Saltarse FASE 3
- **Consecuencia**: Mala UX, usuarios no clickean eventos
- **Soluci√≥n**: SIEMPRE ejecutar FASE 3 antes de FASE 4

### ‚ùå **ERROR 2: Usar API program√°tica en lugar de Puppeteer**
- **S√≠ntoma**: `gemini_factory.execute_global_scrapers()` retorna 0 eventos
- **Causa**: Intentar automatizar sin validar primero
- **Soluci√≥n**: Usar Puppeteer MCP manualmente

### ‚ùå **ERROR 3: Cambiar orden de fases**
- **S√≠ntoma**: Procesos fallidos, datos incompletos
- **Causa**: No seguir orden: Scraping ‚Üí Parsing ‚Üí Im√°genes ‚Üí Import
- **Soluci√≥n**: Seguir SIEMPRE este procedimiento exacto

---

## üìÅ ESTRUCTURA DE ARCHIVOS ESPERADA

```
backend/data/scrapper_results/
‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îî‚îÄ‚îÄ gemini/
‚îÇ       ‚îú‚îÄ‚îÄ cordoba_2025-11-15.txt      (6 KB, 18 eventos)
‚îÇ       ‚îú‚îÄ‚îÄ rosario_2025-11-15.txt      (pendiente)
‚îÇ       ‚îî‚îÄ‚îÄ buenos-aires_2025-11-15.txt (pendiente)
‚îî‚îÄ‚îÄ parsed/
    ‚îî‚îÄ‚îÄ gemini/
        ‚îú‚îÄ‚îÄ cordoba_2025-11-15.json     (12 KB, 18 eventos - SIN im√°genes)
        ‚îú‚îÄ‚îÄ rosario_2025-11-15.json     (pendiente)
        ‚îî‚îÄ‚îÄ buenos-aires_2025-11-15.json (pendiente)
```

---

## üéØ PR√ìXIMOS PASOS

1. ‚úÖ Crear script `fase3_update_images.py`
2. ‚ö†Ô∏è Corregir eventos de C√≥rdoba (agregar im√°genes retroactivamente)
3. ‚è≥ Completar Rosario siguiendo procedimiento correcto
4. ‚è≥ Completar Buenos Aires siguiendo procedimiento correcto
5. ‚è≥ Completar 10 barrios de Buenos Aires
6. üîÑ Renombrar `fase3_import.py` ‚Üí `fase4_import.py` (para claridad)

---

**REGLA DE ORO**:
**NUNCA saltarse FASE 3 - Eventos sin im√°genes = Eventos incompletos**

---

**√öltima actualizaci√≥n**: 2025-11-15 06:30
**Creado por**: Claude Code
**Validado con**: C√≥rdoba (18 eventos)
