# üîÑ Post-Scraping: Siguientes Pasos

## üìã Checklist Post-Scraping

Despu√©s de ejecutar `process_locaciones.py` y tener los archivos JSON:

### 1. ‚úÖ Validaci√≥n de Datos

```bash
# Analizar estructuras JSON generadas
python analyze_json_structures.py

# Verificar que todos los archivos sean v√°lidos
python validate_jsons.py
```

### 2. üìä Normalizaci√≥n

**Tareas**:
- [ ] Normalizar fechas en espa√±ol a formato ISO (YYYY-MM-DD)
- [ ] Validar coordenadas GPS
- [ ] Estandarizar categor√≠as de eventos
- [ ] Limpiar duplicados

**Script recomendado**: `normalize_data.py`

### 3. üóÑÔ∏è Importaci√≥n a Base de Datos

```bash
# Importar eventos a MySQL
python import_all_structures.py

# Verificar importaci√≥n
python verify_import.py

# Ver eventos por locaci√≥n
python show_eventos_by_location.py
```

### 4. üß™ Verificaci√≥n Final

```bash
# Estad√≠sticas generales
python verify_import.py

# Consultas SQL de verificaci√≥n
mysql -h mysql-aiven-arenazl.e.aivencloud.com -P 23108 -u avnadmin -p events
```

**Queries √∫tiles**:
```sql
-- Contar eventos por locaci√≥n
SELECT source, COUNT(*) as total
FROM events
WHERE external_id LIKE 'padron_pr_%'
GROUP BY source;

-- Eventos gratuitos
SELECT * FROM events
WHERE external_id LIKE 'padron_pr_%'
AND is_free = 1;

-- Top categor√≠as
SELECT category, COUNT(*) as total
FROM events
WHERE external_id LIKE 'padron_pr_%'
GROUP BY category
ORDER BY total DESC;
```

### 5. üîó Integraci√≥n con Frontend

**Endpoint API**:
```
GET /api/events?location={ciudad}&source={ciudad}
```

**Ejemplo**:
```bash
curl "http://localhost:8001/api/events?location=San%20Juan&source=San%20Juan"
```

### 6. üìÖ Actualizaci√≥n Mensual

**Proceso recomendado**:
1. Crear script `update_monthly.py` para automatizar
2. Configurar cron job o tarea programada
3. Actualizar solo eventos futuros
4. Archivar eventos pasados

```bash
# Ejecutar actualizaci√≥n mensual
python update_monthly.py --mes diciembre --year 2025
```

### 7. üé® Mejoras Opcionales

- [ ] Agregar im√°genes reales de eventos (en lugar de placeholders)
- [ ] Implementar cache de eventos populares
- [ ] Agregar sistema de favoritos por usuario
- [ ] Notificaciones push para eventos nuevos
- [ ] Integraci√≥n con Google Calendar
- [ ] Sistema de rese√±as y ratings

## üìà M√©tricas de √âxito

**KPIs a medir**:
- N√∫mero total de eventos importados
- % de eventos con toda la informaci√≥n completa
- Distribuci√≥n geogr√°fica de eventos
- Categor√≠as m√°s populares
- Tasa de actualizaci√≥n mensual

## üö® Troubleshooting

### Problema: JSON inv√°lido
**Soluci√≥n**: Revisar respuesta raw de Gemini en campo `raw_response`

### Problema: Fechas incorrectas
**Soluci√≥n**: Mejorar parser de fechas en espa√±ol

### Problema: Coordenadas duplicadas
**Soluci√≥n**: Agregar variaci√≥n aleatoria peque√±a (+/- 0.01¬∞)

### Problema: Eventos duplicados
**Soluci√≥n**: Mejorar generaci√≥n de `external_id` √∫nico

## üìö Scripts Necesarios

Crear estos scripts en la carpeta:

1. `analyze_json_structures.py` - Analizar estructuras
2. `validate_jsons.py` - Validar archivos JSON
3. `normalize_data.py` - Normalizar fechas y datos
4. `import_all_structures.py` - Importar a MySQL
5. `verify_import.py` - Verificar importaci√≥n
6. `show_eventos_by_location.py` - Listar por locaci√≥n
7. `update_monthly.py` - Actualizaci√≥n mensual

## ‚úÖ Estado Actual

- [x] Script de scraping (`process_locaciones.py`)
- [ ] Scraping completado
- [ ] Validaci√≥n de datos
- [ ] Normalizaci√≥n
- [ ] Importaci√≥n a BD
- [ ] Verificaci√≥n final
- [ ] Integraci√≥n frontend

---

**Pr√≥ximo paso**: Ejecutar `python process_locaciones.py` para comenzar el scraping.
