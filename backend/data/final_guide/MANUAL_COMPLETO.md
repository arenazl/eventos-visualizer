# ğŸ“– MANUAL COMPLETO - SISTEMA ELÃSTICO DE SCRAPING DE EVENTOS

**VersiÃ³n:** 1.2
**Fecha:** 2025-11-23
**Sistema:** Independiente de sitios e independiente de regiones

---

## âš¡ CHECKLIST RÃPIDO - COPIAR Y PEGAR

### ğŸ”´ REGLA #1: LEER ESTE DOCUMENTO PRIMERO
Antes de ejecutar CUALQUIER comando, lee este documento completo.

---

### Para scrapear UNA ciudad nueva:

#### FASE 1 - SCRAPING (Gemini/Felo)
```
1. Ir a: https://felo.ai o http://gemini.google.com

2. Usar EXACTAMENTE este prompt (reemplazar {CIUDAD, PAIS}):

   me podrÃ­as pasar por lo menos 20 eventos, fiestas, festivales, encuentros en {CIUDAD, PAIS} desde hoy hasta las las proximas semanas, si puede ser que incluya su nombre, descripciÃ³n, fecha, lugar, direcciÃ³n, precio y alguna info extra que tengas!

3. Copiar respuesta completa
4. Guardar en: backend/data/scrapper_results/raw/{sitio}/{ciudad}_YYYY-MM-DD.txt
```

#### FASE 2 - PARSING + IMÃGENES (ğŸ¤– CON IA)
```bash
cd backend/data/final_guide/scripts && python parse_raw.py
```
> **CaracterÃ­sticas:**
> - Usa IA (Ollama/Grok/OpenAI) para parsear CUALQUIER formato
> - Extrae ciudad, paÃ­s, provincia automÃ¡ticamente
> - Busca imÃ¡genes con Google Images API
> - Categoriza eventos con IA
>
> **Requisitos:**
> - `ollama serve` corriendo, o GROK_API_KEY/OPENAI_API_KEY en .env
> - GOOGLE_API_KEY y GOOGLE_CX en .env (para imÃ¡genes)
>
> **Opciones:**
> - `--file archivo.txt` - Procesa solo un archivo
> - `--no-images` - Omite bÃºsqueda de imÃ¡genes (mÃ¡s rÃ¡pido)
> - `--dry-run` - Solo muestra quÃ© se procesarÃ­a

#### FASE 3 - IMPORT MYSQL
```bash
cd backend/data/scripts && python auto_import.py
```

## ğŸ¯ FILOSOFÃA DEL SISTEMA

Este sistema estÃ¡ diseÃ±ado para ser **100% elÃ¡stico y configurable**:

- âœ… **Independiente de sitios**: Agregar nuevos scrapers sin modificar cÃ³digo core
- âœ… **Independiente de regiones**: Funciona con cualquier paÃ­s/ciudad/barrio
- âœ… **Fases separadas**: Scrape â†’ Parse â†’ Import (cada fase independiente)
- âœ… **Configurable**: Todos los parÃ¡metros en archivos de configuraciÃ³n
- âœ… **Escalable**: De 1 ciudad a 100+ ciudades sin cambios de arquitectura

---

## ğŸ“‚ ESTRUCTURA DE ARCHIVOS

```
backend/data/
â”œâ”€â”€ final_guide/                    # ğŸ“š GUÃAS Y SCRIPTS MAESTROS
â”‚   â”œâ”€â”€ MANUAL_COMPLETO.md         # Este archivo
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ sites.json             # ConfiguraciÃ³n de sitios a scrapear
â”‚   â”‚   â””â”€â”€ regions.json           # ConfiguraciÃ³n de regiones
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   # === MÃ“DULOS COMPARTIDOS ===
â”‚   â”‚   â”œâ”€â”€ region_utils.py        # ğŸŒ Mapeo dinÃ¡mico Ciudadâ†’PaÃ­sâ†’Provincia (lee de regions/)
â”‚   â”‚   â”œâ”€â”€ event_utils.py         # ğŸ·ï¸ CategorizaciÃ³n y normalizaciÃ³n de eventos
â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   # === SCRIPTS POR FUENTE ===
â”‚   â”‚   â”œâ”€â”€ scrape_gemini.js       # Scraping: Instrucciones Puppeteer para Gemini
â”‚   â”‚   â”œâ”€â”€ parse_gemini.py        # Parsing: RAW (tabs) â†’ JSON para Gemini
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ scrape_felo.js         # Scraping: Instrucciones Puppeteer para Felo
â”‚   â”‚   â”œâ”€â”€ parse_felo.py          # Parsing: RAW (TSV o lÃ­neas) â†’ JSON para Felo
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ scrape_grok.js         # Scraping: Puppeteer para Grok (DISABLED - captcha)
â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   # === SCRIPTS GENERALES ===
â”‚   â”‚   â”œâ”€â”€ fase4_import.py        # FASE 3: Import a MySQL
â”‚   â”‚   â””â”€â”€ pipeline_completo.py   # Pipeline automatizado
â”‚   â”‚
â”‚   â””â”€â”€ readme.md                   # Referencias rÃ¡pidas
â”‚
â”œâ”€â”€ reports/                        # FASE 5: Reportes HTML generados
â”‚   â””â”€â”€ eventos_2025-11-23.html
â”‚
â”œâ”€â”€ scrapper_results/
â”‚   â”œâ”€â”€ raw/                        # FASE 1: Respuestas crudas
â”‚   â”‚   â”œâ”€â”€ gemini/
â”‚   â”‚   â”‚   â””â”€â”€ buenosaires_2025-11-22.txt
â”‚   â”‚   â””â”€â”€ felo/
â”‚   â”‚       â””â”€â”€ cordoba_2025-11-22.txt
â”‚   â”‚
â”‚   â””â”€â”€ parsed/                     # FASE 2: JSON estructurados
â”‚       â”œâ”€â”€ gemini/
â”‚       â”‚   â””â”€â”€ buenosaires_2025-11-22.json
â”‚       â””â”€â”€ felo/
â”‚           â””â”€â”€ cordoba_2025-11-22.json
â”‚
â””â”€â”€ regions/                        # DefiniciÃ³n de regiones
    â””â”€â”€ latinamerica/
        â””â”€â”€ sudamerica/
            â””â”€â”€ argentina.json
```

---

## ğŸŒ MÃ“DULOS COMPARTIDOS

### 1. region_utils.py - Mapeo Ciudadâ†’PaÃ­sâ†’Provincia

Mapea **dinÃ¡micamente** ciudad â†’ paÃ­s â†’ provincia leyendo los archivos JSON de `backend/data/regions/`.

**CaracterÃ­sticas:**
- Sin hardcodeo: Lee de los archivos de regiones existentes
- Recursivo: Funciona con cualquier estructura (regions, provinces, communities, states)
- Normalizado: Maneja acentos, mayÃºsculas, guiones automÃ¡ticamente
- Cache: Carga una vez, reutiliza en toda la sesiÃ³n

**Uso:**
```python
from region_utils import get_pais_from_ciudad, get_provincia_from_ciudad

pais = get_pais_from_ciudad('Paris')           # -> 'Francia'
pais = get_pais_from_ciudad('Barcelona')       # -> 'EspaÃ±a'
pais = get_pais_from_ciudad('Florianopolis')   # -> 'Brasil'

provincia = get_provincia_from_ciudad('Barcelona')     # -> 'CataluÃ±a'
provincia = get_provincia_from_ciudad('Florianopolis') # -> 'Santa Catarina'
provincia = get_provincia_from_ciudad('Mendoza')       # -> 'Mendoza'
```

**Agregar nuevas ciudades:**
Editar el archivo JSON en `backend/data/regions/`:
- regions/europa/europa-occidental/francia.json
- regions/latinamerica/sudamerica/argentina.json

---

### 2. event_utils.py - CategorizaciÃ³n y NormalizaciÃ³n

Funciones compartidas para categorizar eventos y normalizar fechas.

**Funciones:**
- `categorize_event(nombre, descripcion)` - Retorna (category, subcategory)
- `normalize_fecha(fecha_str)` - Convierte fechas a formato YYYY-MM-DD

**CategorÃ­as disponibles:**
| Category | Subcategories |
|----------|---------------|
| music | rock, pop, jazz, electronic, folk, classical, hiphop, other |
| sports | football, basketball, tennis, running, other |
| cultural | theater, museum, exhibition, literature, cinema, other |
| nightlife | party, club, bar, other |
| entertainment | comedy, circus, magic, other |
| food | restaurant, festival, market, other |
| tech | conference, hackathon, meetup, other |
| other | general |

**Uso:**
```python
from event_utils import categorize_event, normalize_fecha

# CategorizaciÃ³n automÃ¡tica por keywords
categorize_event('Concierto de Rock', 'Banda de rock')  # -> ('music', 'rock')
categorize_event('SC21K', 'Media maratÃ³n 21km')         # -> ('sports', 'running')
categorize_event('Hans Zimmer', 'Concierto orquestal')  # -> ('music', 'classical')

# NormalizaciÃ³n de fechas
normalize_fecha('8 noviembre 2025')       # -> '2025-11-08'
normalize_fecha('Del 7 al 9 de noviembre') # -> '2025-11-07'
```

**âš ï¸ IMPORTANTE:** Todos los parsers (`parse_felo.py`, `parse_gemini.py`) y `auto_import.py` usan estas funciones compartidas. NO duplicar cÃ³digo.

---

## ğŸ“œ SCRIPTS POR FUENTE

### Principio fundamental:
**CADA FUENTE TIENE 2 ARCHIVOS:**
1. `scrape_{fuente}.js` - Instrucciones para Puppeteer MCP (selectores, pasos)
2. `parse_{fuente}.py` - Parser especÃ­fico para el formato de respuesta de esa fuente

### ğŸ“ Gemini
| Archivo | DescripciÃ³n |
|---------|-------------|
| `scrape_gemini.js` | Selectores: `.ql-editor`, `button[aria-label='Enviar mensaje']` |
| `parse_gemini.py` | Parsea formato TABLA con tabs (NÂ° \t Nombre \t DescripciÃ³n \t ...) |

### ğŸ“ Felo
| Archivo | DescripciÃ³n |
|---------|-------------|
| `scrape_felo.js` | Selectores: `textarea`, `button[aria-label="Send"]`, `.prose` |
| `parse_felo.py` | Parsea formato TSV (tabs) o LÃNEAS (auto-detecta) |

### ğŸ“ Grok (DISABLED)
| Archivo | DescripciÃ³n |
|---------|-------------|
| `scrape_grok.js` | Selectores documentados pero NO USAR - tiene captcha Cloudflare |

### âš ï¸ IMPORTANTE:
- `parse_felo.py` auto-detecta el formato (TSV con tabs o lÃ­nea por lÃ­nea)
- `parse_gemini.py` parsea tablas con tabs
- Ambos usan `region_utils.py` para mapear ciudad â†’ paÃ­s dinÃ¡micamente

---

## ğŸ”§ CONFIGURACIÃ“N

### 1. Archivo `config/sites.json`

Define QUÃ‰ sitios scrapear y CÃ“MO hacerlo:

```json
{
  "ai_scrapers": [
    {
      "id": "gemini",
      "name": "Google Gemini",
      "url": "https://gemini.google.com",
      "method": "puppeteer",
      "selectors": {
        "input": ".ql-editor",
        "submit": "button[aria-label='Enviar mensaje']",
        "response": ".model-response-text"
      },
      "wait_time": 15,
      "enabled": true
    },
    {
      "id": "felo",
      "name": "Felo AI",
      "url": "https://felo.ai",
      "method": "puppeteer",
      "selectors": {
        "input": "textarea[placeholder*='search']",
        "submit": "button[type='submit']",
        "response": ".answer-content"
      },
      "wait_time": 20,
      "enabled": true
    },
    {
      "id": "grok",
      "name": "Grok",
      "url": "https://grok.com",
      "method": "puppeteer",
      "selectors": {
        "input": "textarea",
        "submit": "button[aria-label='Send']",
        "response": ".response-text"
      },
      "wait_time": 15,
      "enabled": false,
      "disabled_reason": "Captcha de Cloudflare no se puede automatizar"
    }
  ],

  "traditional_scrapers": [
    {
      "id": "buenosaliens",
      "name": "Buenos Aliens Agenda",
      "url": "https://www.buenosaliens.com/#agenda",
      "method": "selenium",
      "selectors": {
        "event_cards": ".event-item",
        "title": "h3.event-title",
        "date": ".event-date",
        "venue": ".event-venue"
      },
      "enabled": true
    }
  ]
}
```

### 2. Archivo `config/regions.json`

Define DÃ“NDE scrapear (reutiliza estructura existente):

```json
{
  "source": "../regions/latinamerica/sudamerica/argentina.json",
  "selection": {
    "mode": "all",
    "cities": ["Buenos Aires", "CÃ³rdoba", "Rosario"],
    "include_barrios": true
  }
}
```

### 3. Archivo `config/prompts.json`

Define el PROMPT para cada tipo de scraper:

```json
{
  "ai_scrapers": {
    "default_template": "me podrÃ­as pasar por lo menos 20 eventos, fiestas, festivales, encuentros en {lugar} desde hoy hasta las las proximas semanas, si puede ser que incluya su nombre, descripciÃ³n, fecha, lugar, direcciÃ³n, precio y alguna info extra que tengas!",

    "variations": {
      "gemini": "me podrÃ­as pasar por lo menos 20 eventos, fiestas, festivales, encuentros en {lugar} desde hoy hasta las las proximas semanas, si puede ser que incluya su nombre, descripciÃ³n, fecha, lugar, direcciÃ³n, precio y alguna info extra que tengas!",

      "felo": "me podrÃ­as pasar por lo menos 20 eventos, fiestas, festivales, encuentros en {lugar} desde hoy hasta las las proximas semanas, si puede ser que incluya su nombre, descripciÃ³n, fecha, lugar, direcciÃ³n, precio y alguna info extra que tengas!",

      "grok": "me podrÃ­as pasar por lo menos 20 eventos, fiestas, festivales, encuentros en {lugar} desde hoy hasta las las proximas semanas, si puede ser que incluya su nombre, descripciÃ³n, fecha, lugar, direcciÃ³n, precio y alguna info extra que tengas!"
    }
  }
}
```

---

## ğŸš€ FASES DEL PROCESO

### FASE 1: SCRAPING (Obtener respuestas crudas)

**Objetivo**: Navegar a cada sitio y guardar respuestas RAW sin procesar

**MÃ©todo**: Usar Puppeteer MCP siguiendo las instrucciones de `scrape_{fuente}.js`

**Scripts de referencia**:
| Fuente | Script | DescripciÃ³n |
|--------|--------|-------------|
| Gemini | `scrape_gemini.js` | Selectores y pasos para gemini.google.com |
| Felo | `scrape_felo.js` | Selectores y pasos para felo.ai |
| Grok | `scrape_grok.js` | âš ï¸ DISABLED - captcha Cloudflare |


**Proceso manual con Puppeteer MCP**:
```javascript
// 1. Navegar (ejemplo Gemini)
mcp__puppeteer__puppeteer_navigate({ url: "https://gemini.google.com" })

// 2. Llenar prompt
mcp__puppeteer__puppeteer_fill({ selector: ".ql-editor", value: "eventos en Buenos Aires..." })

// 3. Click enviar
mcp__puppeteer__puppeteer_click({ selector: "button[aria-label='Enviar mensaje']" })

// 4. Esperar y extraer
// Esperar 15-30 segundos
mcp__puppeteer__puppeteer_evaluate({ script: "document.querySelector('.model-response-text')?.innerText" })

// 5. Guardar en: raw/{fuente}/{ciudad}_{fecha}.txt
```

**Salida**: Archivos `.txt` en `scrapper_results/raw/{site_id}/{ciudad}_{fecha}.txt`

**Ejemplo de salida**:
```
scrapper_results/raw/gemini/buenosaires_2025-11-22.txt
scrapper_results/raw/felo/cordoba_2025-11-22.txt
```

---

### FASE 2: PARSING (Convertir RAW a JSON estructurado)

**Objetivo**: Leer archivos RAW y convertirlos a JSON con estructura estÃ¡ndar

**Scripts por fuente**:
| Fuente | Parser | Formato que procesa |
|--------|--------|---------------------|
| Gemini | `parse_gemini.py` | Tablas con tabs (NÂ° \t Nombre \t DescripciÃ³n...) |
| Felo | `parse_felo.py` | LÃ­neas con prefijos (DescripciÃ³n: ...\nFecha: ...) |

**Comandos**:
```bash
# Parsear archivos de Gemini (formato tabla)
cd backend/data/final_guide/scripts
python parse_gemini.py

# Parsear archivos de Felo (formato lÃ­neas)
python parse_felo.py

# Con opciones
python parse_gemini.py --reparse     # Re-parsear todo
python parse_gemini.py --debug       # Mostrar detalles
```

**âš ï¸ IMPORTANTE - Elegir el parser correcto**:
- Si el archivo RAW tiene tabs (`\t`) entre campos â†’ usar `parse_gemini.py`
- Si el archivo RAW tiene lÃ­neas tipo `DescripciÃ³n: ...` â†’ usar `parse_felo.py`
- `parse_felo.py` tambiÃ©n procesa archivos de Gemini que vengan en formato lÃ­neas

**Salida**: Archivos `.json` en `scrapper_results/parsed/{site_id}/{ciudad}_{fecha}.json`

**Estructura JSON estÃ¡ndar**:
```json
[
  {
    "nombre": "Festival de Jazz en Palermo",
    "descripcion": "Gran festival de jazz al aire libre",
    "fecha": "2025-11-20",
    "lugar": "Parque 3 de Febrero",
    "direccion": "Av. del Libertador 3260",
    "barrio": "Palermo",
    "precio": "Gratis",
    "ciudad": "Buenos Aires",
    "provincia": "Ciudad AutÃ³noma de Buenos Aires",
    "neighborhood": "Palermo",
    "category": "music",
    "subcategory": "jazz",
    "pais": "Argentina",
    "es_gratis": true,
    "source": "gemini"
  }
]
```

**âš ï¸ CAMPOS OBLIGATORIOS generados automÃ¡ticamente por los parsers:**
- `pais`: Detectado dinÃ¡micamente desde `region_utils.py`
- `provincia`: Detectado dinÃ¡micamente desde `region_utils.py`
- `category/subcategory`: Inferidos desde `event_utils.py`

---

### FASE 3: IMPORT (Insertar en MySQL con detecciÃ³n de duplicados)

**Objetivo**: Leer JSONs parseados e insertar en MySQL evitando duplicados

**Script**: `backend/data/scripts/auto_import.py`

**âš ï¸ IMPORTANTE**: Este script usa las funciones compartidas de `event_utils.py` y `region_utils.py`

**Comando**:
```bash
# Importar TODO lo que estÃ¡ en parsed/
cd backend/data/scripts
python auto_import.py

# Ver quÃ© se importarÃ­a sin hacerlo
python auto_import.py --dry-run

# Reiniciar log y reprocesar todo
python auto_import.py --reset
```

**DetecciÃ³n de duplicados**:
- âœ… **Duplicado exacto**: Mismo tÃ­tulo, ciudad y fecha
- âœ… **Duplicado parcial**: TÃ­tulos con 80%+ palabras en comÃºn
- âœ… **Log detallado**: Muestra quÃ© pasÃ³ con cada evento

**Ejemplo de salida**:
```
================================================================================
âœ¨ IMPORTACIÃ“N COMPLETADA
================================================================================

ğŸ“Š Archivos procesados: 3
âœ… Eventos insertados: 42
â­ï¸  Eventos duplicados (ya existÃ­an): 18
   â€¢ Duplicados exactos (tÃ­tulo completo igual): 12
   â€¢ Duplicados parciales (tÃ­tulos similares ~80%): 6
âŒ Errores: 2

ğŸ“ˆ Tasa de Ã©xito: 95.5%
================================================================================
```

---

### FASE 4: IMÃGENES (Agregar imÃ¡genes a eventos)

**Objetivo**: Buscar y agregar imÃ¡genes de Google para cada evento

**Script**: `backend/data/scripts/update_event_images.js`

**Requisitos en `.env`**:
```bash
GOOGLE_API_KEY=tu_api_key_de_google
GOOGLE_CX=tu_custom_search_engine_id
```

**CÃ³mo obtener las credenciales**:
1. **GOOGLE_API_KEY**:
   - Ir a https://console.cloud.google.com/apis/credentials
   - Crear una API Key
   - Habilitar "Custom Search API"
2. **GOOGLE_CX**:
   - Ir a https://programmablesearchengine.google.com/
   - Crear un motor de bÃºsqueda
   - Copiar el "Search engine ID"

**Comando**:
```bash
cd backend/data/scripts
node update_event_images.js
```

**LÃ³gica de bÃºsqueda (Triple Fallback)**:
1. **Intento 1**: `{tÃ­tulo completo} {venue} {ciudad} event`
2. **Intento 2**: `{primeras 3 palabras del tÃ­tulo} {ciudad} event`
3. **Intento 3**: `{venue} {ciudad}`

**Rate Limiting**:
- 1 segundo entre cada bÃºsqueda
- Si Google devuelve 429 (rate limit), guarda progreso y se detiene
- Los eventos que ya tienen `image_url` se skipean

**Ejemplo de salida**:
```
======================================================================
ğŸ–¼ï¸  AGREGANDO IMÃGENES A EVENTOS
======================================================================
ğŸ“‚ Carpeta base: scrapper_results/parsed

ğŸ” Fuentes encontradas: gemini, felo

ğŸ“ Procesando fuente: GEMINI
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“Š 5 archivos JSON encontrados en gemini

ğŸ“„ Procesando: buenosaires_2025-11-22.json
  [1/20] Festival del SÃ¡ndwich...
    âœ… Imagen (tÃ­tulo completo)
  [2/20] FUTCON 2025...
    âœ… Imagen (tÃ­tulo reducido)
  ğŸ’¾ 18 imÃ¡genes agregadas

======================================================================
ğŸ‰ PROCESO COMPLETADO
======================================================================
ğŸ“ Fuentes procesadas: 2 (gemini, felo)
ğŸ“Š Archivos procesados: 11
ğŸ–¼ï¸  Total imÃ¡genes agregadas: 145
======================================================================
```

**âš ï¸ LÃMITES DE GOOGLE CUSTOM SEARCH API**:
- **Gratis**: 100 bÃºsquedas/dÃ­a
- **Pago**: $5 por cada 1000 bÃºsquedas adicionales
- **RecomendaciÃ³n**: Ejecutar despuÃ©s de cada batch de parsing, no todo junto

---

### FASE 4.5: LIMPIAR URLs INVÃLIDAS (CRÃTICO)

**Problema descubierto**: Google Custom Search API devuelve URLs que **NO son pÃºblicamente accesibles**:

| PatrÃ³n de URL | Problema |
|---------------|----------|
| `x-raw-image:///...` | URLs internas de Google, no son HTTP vÃ¡lidas |
| `lookaside.fbsbx.com` | Facebook bloquea hotlinking |
| `lookaside.instagram.com` | Instagram bloquea hotlinking |
| `tiktok.com/api/img` | TikTok requiere autenticaciÃ³n |
| `p16-common-sign.tiktokcdn` | CDN de TikTok con tokens temporales |

**SÃ­ntoma**: Las imÃ¡genes se ven en la consola como "agregadas" pero NO cargan en el HTML.

**Script de limpieza**: `scripts/fix_invalid_images.py`

**Comando**:
```bash
cd backend/data/scripts

# 1. Limpiar URLs invÃ¡lidas (borra image_url de eventos con URLs malas)
python fix_invalid_images.py

# 2. Re-ejecutar bÃºsqueda de imÃ¡genes (ahora buscarÃ¡ nuevas para los limpiados)
node update_event_images.js
```

**QuÃ© hace el script**:
1. Recorre todos los JSONs en `parsed/`
2. Detecta URLs con patrones invÃ¡lidos
3. **Elimina** el campo `image_url` de esos eventos
4. Guarda el JSON actualizado
5. Ahora `update_event_images.js` los detectarÃ¡ como "sin imagen" y buscarÃ¡ nuevas

**Ejemplo de salida**:
```
============================================================
LIMPIANDO URLs DE IMAGENES INVALIDAS
============================================================

[DIR] Procesando: gemini

  [FILE] buenosaires_2025-11-22.json
  - Limpiando: Festival del Sandwich...
    URL invalida: x-raw-image:///cff9756fc87d8e92752bb...
  - Limpiando: Dia Nacional del Kimchi...
    URL invalida: https://lookaside.instagram.com/seo/...
  [OK] 8 URLs limpiadas

============================================================
TOTAL URLs LIMPIADAS: 58
============================================================
```

**âš ï¸ IMPORTANTE**: Siempre ejecutar `fix_invalid_images.py` DESPUÃ‰S de `update_event_images.js` para limpiar las URLs malas, y luego re-ejecutar `update_event_images.js` para buscar reemplazos.

---

### FASE 5: GENERAR REPORTE HTML

**Objetivo**: Crear un reporte visual de todos los eventos con imÃ¡genes

**Script**: `scripts/generar_reporte_html.py`

**Comando**:
```bash
cd backend/data/scripts
python generar_reporte_html.py
```

**Salida**: `reports/eventos_YYYY-MM-DD.html`

**Para ver el reporte con imÃ¡genes** (importante por CORS):
```bash
cd backend/data/reports
python -m http.server 8080
# Abrir: http://localhost:8080/eventos_2025-11-23.html
```

**âš ï¸ NOTA**: Si abres el HTML directamente desde el explorador de archivos (`file://`), muchas imÃ¡genes no cargarÃ¡n por restricciones de CORS. Siempre servir con un servidor HTTP.

---

## ğŸ”„ FLUJO COMPLETO RECOMENDADO

### Resumen de las 6 Fases

| Fase | Script | UbicaciÃ³n | Input | Output |
|------|--------|-----------|-------|--------|
| **FASE 1** | Puppeteer MCP + `scrape_{fuente}.js` | `final_guide/scripts/` | Prompt + Ciudad | `raw/{fuente}/{ciudad}_{fecha}.txt` |
| **FASE 2** | `parse_gemini.py` / `parse_felo.py` | `final_guide/scripts/` | Archivos RAW | `parsed/{fuente}/{ciudad}_{fecha}.json` |
| **FASE 3** | `auto_import.py` | `data/scripts/` | Archivos JSON | Registros en MySQL |
| **FASE 4** | `update_event_images.js` | `data/scripts/` | Archivos JSON | JSON con `image_url` agregado |
| **FASE 4.5** | `fix_invalid_images.py` | `data/scripts/` | JSON con URLs malas | JSON con URLs vÃ¡lidas |
| **FASE 5** | `generar_reporte_html.py` | `data/scripts/` | Archivos JSON | `reports/eventos_YYYY-MM-DD.html` |

**MÃ³dulos compartidos** (en `final_guide/scripts/`):
- `region_utils.py` - Mapeo ciudadâ†’paÃ­sâ†’provincia
- `event_utils.py` - CategorizaciÃ³n y normalizaciÃ³n

### Flujo paso a paso (RECOMENDADO)

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FASE 1: SCRAPING (usar Puppeteer MCP manualmente)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ver instrucciones en final_guide/scripts/scrape_gemini.js o scrape_felo.js
# Guardar respuesta en: scrapper_results/raw/{fuente}/{ciudad}_{fecha}.txt

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FASE 2: PARSING (usa event_utils.py y region_utils.py automÃ¡ticamente)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
cd backend/data/final_guide/scripts

# Si el RAW tiene formato tabla (tabs):
python parse_gemini.py

# Si el RAW tiene formato lÃ­neas (DescripciÃ³n: ...):
python parse_felo.py

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FASE 3: IMPORT A MYSQL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
cd backend/data/scripts
python auto_import.py           # Importar nuevos
python auto_import.py --dry-run # Ver quÃ© se importarÃ­a
python auto_import.py --reset   # Reimportar todo

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FASE 4: IMÃGENES (buscar imÃ¡genes de Google)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
cd backend/data/scripts
node update_event_images.js      # Agregar imÃ¡genes a JSONs

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FASE 4.5: LIMPIAR URLs INVÃLIDAS (CRÃTICO - siempre ejecutar)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
python fix_invalid_images.py     # Elimina URLs que no cargan (Facebook, Instagram, TikTok, x-raw)
node update_event_images.js      # Re-buscar imÃ¡genes para los limpiados

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FASE 5: GENERAR REPORTE HTML
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
python generar_reporte_html.py   # Genera reports/eventos_YYYY-MM-DD.html

# Para ver el reporte (necesario por CORS):
cd ../reports && python -m http.server 8080
# Abrir: http://localhost:8080/eventos_2025-11-23.html
```

### Orden de rotaciÃ³n de fuentes (evitar detecciÃ³n)

```
Ciudad 1 â†’ Gemini
Ciudad 2 â†’ Felo
Ciudad 3 â†’ Gemini
Ciudad 4 â†’ Felo
...
```

**âš ï¸ NO usar Grok** - tiene captcha de Cloudflare que no se puede automatizar

---

## ğŸ“Š MONITOREO Y LOGS

### Logs automÃ¡ticos generados:

```
logs/
â”œâ”€â”€ fase1_scrape_2025-11-14.log      # QuÃ© se scrapeÃ³, errores, tiempos
â”œâ”€â”€ fase2_parse_2025-11-14.log       # QuÃ© se parseÃ³, eventos por archivo
â””â”€â”€ fase3_import_2025-11-14.log      # Detalles de importaciÃ³n, duplicados
```

### Verificar estado del sistema:

```bash
# Ver archivos RAW disponibles
ls backend/data/scrapper_results/raw/*/

# Ver archivos PARSED disponibles
ls backend/data/scrapper_results/parsed/*/

# Ver cuÃ¡ntos eventos hay por fuente
for file in backend/data/scrapper_results/parsed/*/*.json; do
  echo "$file: $(cat "$file" | grep -c '"nombre"') eventos"
done

# Ver distribuciÃ³n de paÃ­ses en la DB
mysql -u root -p events -e "SELECT country, COUNT(*) as cnt FROM events GROUP BY country ORDER BY cnt DESC LIMIT 10;"
```

---

## ğŸ› ï¸ AGREGAR NUEVOS SITIOS

### Ejemplo: Agregar "Perplexity AI"

**1. Editar `config/sites.json`**:

```json
{
  "id": "perplexity",
  "name": "Perplexity AI",
  "url": "https://perplexity.ai",
  "method": "puppeteer",
  "selectors": {
    "input": "textarea[placeholder*='Ask']",
    "submit": "button[type='submit']",
    "response": ".answer-container"
  },
  "wait_time": 12,
  "enabled": true
}
```

**2. Agregar prompt en `config/prompts.json`**:

```json
"perplexity": "lista eventos en {lugar} este mes con nombre, fecha, lugar y precio"
```

**3. Ejecutar scraping manualmente** usando Puppeteer MCP siguiendo las instrucciones del documento.

**Â¡Listo!** No hace falta modificar cÃ³digo del parser - usa auto-detecciÃ³n de formato.

---

## ğŸŒ AGREGAR NUEVAS REGIONES

### Ejemplo: Agregar ciudades de MÃ©xico

**1. Crear archivo de regiÃ³n** (`regions/latinamerica/norteamerica/mexico.json`):

```json
{
  "country": "MÃ©xico",
  "cities": [
    {
      "name": "Ciudad de MÃ©xico",
      "barrios": [
        {"name": "Roma Norte"},
        {"name": "Condesa"},
        {"name": "Polanco"}
      ]
    },
    {
      "name": "Guadalajara",
      "barrios": []
    }
  ]
}
```

**2. Actualizar `config/regions.json`**:

```json
{
  "sources": [
    "../regions/latinamerica/sudamerica/argentina.json",
    "../regions/latinamerica/norteamerica/mexico.json"
  ],
  "selection": {
    "mode": "all"
  }
}
```

**3. Ejecutar scraping manualmente** con Puppeteer MCP y luego:

```bash
# Parsear los archivos RAW
cd backend/data/final_guide/scripts
python parse_felo.py    # Si tiene formato lÃ­neas
python parse_gemini.py  # Si tiene formato tabla con tabs
```

---

## âš™ï¸ CONFIGURACIÃ“N AVANZADA

### Delays y rate limiting

**En `config/sites.json`**:
```json
{
  "id": "gemini",
  "rate_limit": {
    "requests_per_minute": 3,
    "delay_between_requests": 20,
    "delay_on_error": 60,
    "max_retries": 3
  }
}
```

### Proxy y headers

**En `config/sites.json`**:
```json
{
  "id": "gemini",
  "proxy": {
    "enabled": true,
    "url": "http://proxy.example.com:8080"
  },
  "headers": {
    "User-Agent": "Mozilla/5.0...",
    "Accept-Language": "es-AR,es;q=0.9"
  }
}
```

---

## ğŸ› TROUBLESHOOTING

### Problema: Scraping falla con "timeout"

**SoluciÃ³n**: Aumentar `wait_time` en `config/sites.json`

```json
"wait_time": 30  // Aumentar de 15 a 30 segundos
```

### Problema: No se detectan eventos en parsing

**SoluciÃ³n**: Ejecutar con `--debug` para ver el raw text

```bash
cd backend/data/final_guide/scripts
python parse_gemini.py --debug    # Para archivos de Gemini
python parse_felo.py              # Para archivos de Felo (auto-detecta formato)
```

### Problema: Muchos duplicados parciales

**SoluciÃ³n**: Ajustar threshold de similitud en `config/import.json`

```json
{
  "duplicate_detection": {
    "partial_match_threshold": 0.85  // De 0.80 a 0.85 (mÃ¡s estricto)
  }
}
```

---

## ğŸ“ MEJORES PRÃCTICAS

### âœ… HACER:
- Ejecutar FASE 1 completa antes de pasar a FASE 2
- Usar `--dry-run` antes de importar a producciÃ³n
- Mantener logs por al menos 30 dÃ­as
- Ejecutar en horarios de bajo trÃ¡fico (madrugada)
- Usar delays de 20+ segundos entre AI requests

### âŒ NO HACER:
- Ejecutar las 3 fases simultÃ¡neamente (riesgo de bloqueo)
- Modificar archivos RAW manualmente
- Eliminar logs antes de verificar imports
- Scrapear mÃ¡s de 10 ciudades sin delays

---

## ğŸ”® ROADMAP

**v1.1** (PrÃ³xima versiÃ³n):
- [ ] Soporte para scraping con Bright Data
- [ ] Parser con GPT-4 para mejor extracciÃ³n
- [ ] Dashboard web para monitoreo
- [ ] Notificaciones por Telegram cuando termina scraping

**v2.0** (Futuro):
- [ ] Auto-scaling segÃºn volumen de ciudades
- [ ] Machine learning para detectar duplicados
- [ ] API REST para ejecutar fases remotamente
- [ ] IntegraciÃ³n con Google Calendar automÃ¡tica

---

## ğŸ“ SOPORTE

**Logs**: Todos los logs estÃ¡n en `logs/`
**Config**: Toda la config estÃ¡ en `config/`
**Scripts**: Scripts maestros en `scripts/`

---

## ğŸ¤– INSTRUCCIONES ESPECÃFICAS POR SITIO (Puppeteer MCP)

### ConfiguraciÃ³n General del Browser

```javascript
// SIEMPRE usar ventana incÃ³gnito y maximizada para evitar detecciÃ³n
launchOptions: {
  "headless": false,
  "args": ["--incognito", "--start-maximized"]
}
```

**IMPORTANTE**: Rotar el orden de los sitios entre ejecuciones para evitar patrones detectables.

---

### ğŸ”· GEMINI (gemini.google.com)

**URL**: `https://gemini.google.com`

**Paso a paso**:
1. Navegar a la URL con incÃ³gnito + maximizado
2. Esperar 2-3 segundos para que cargue
3. Llenar el campo de texto:
   - Selector: `.ql-editor, textarea, [contenteditable='true']`
4. Hacer clic en enviar:
   - Selector: `button[aria-label='Enviar mensaje']`
5. Esperar 15-30 segundos para la respuesta
6. Extraer texto de respuesta:
   - Buscar elementos con clase `.model-response-text` o `[data-message-author-role="model"]`

**Prompt a usar**:
```
me podrÃ­as pasar por lo menos 20 eventos, fiestas, festivales, encuentros en {lugar} a partir de hoy y las prÃ³ximas semanas?, si puede ser que incluya su nombre, descripciÃ³n, fecha, lugar, direcciÃ³n, barrio, precio y alguna info extra que tengas! En formato de tabla con tabs separando las columnas: NÂ°	Nombre del Evento	DescripciÃ³n	Fecha	Lugar / DirecciÃ³n	Barrio	Precio (ARS)	Info Extra
```

**Notas**:
- Gemini puede pedir login ocasionalmente - ignorar y usar sin login
- El formato de tabla con tabs facilita el parsing posterior

---

### ğŸ”¶ FELO (felo.ai) - PROCESO VERIFICADO âœ…

**URL**: `https://felo.ai`

**ConfiguraciÃ³n del browser**:
```javascript
// IMPORTANTE: Viewport grande para ver toda la interfaz
launchOptions: {
  "headless": false,
  "args": ["--incognito", "--start-maximized", "--window-size=1920,1080"]
}
// Screenshot con width: 1920, height: 1080
```

**Paso a paso VERIFICADO (2025-11-22)**:
1. Navegar a `https://felo.ai` con incÃ³gnito + viewport 1920x1080
2. Esperar 2-3 segundos para que cargue
3. Llenar el campo de texto:
   - Selector: `textarea` (campo "Ask anything...")
4. **CRÃTICO**: Hacer clic en el botÃ³n de enviar:
   - Selector: `button[aria-label="Send"]` âœ… FUNCIONA
   - âŒ NO usar: `button[class*='bg-primary']` (no funciona)
   - âŒ NO usar: `form.submit()` (recarga la pÃ¡gina)
5. **âš ï¸ POPUP DE SUSCRIPCIÃ“N**: A veces aparece una pÃ¡gina para elegir plan
   - Buscar y hacer clic en el botÃ³n que contenga "gratis" o "free"
   - Ver cÃ³digo JavaScript abajo
6. Esperar 20-30 segundos para la respuesta (usa 49 fuentes)
7. Extraer texto de respuesta:
   - Selector: `.prose` o buscar en el contenedor principal
   - La respuesta aparece con formato estructurado (eventos numerados)

**Prompt a usar**:
```
dame por lo menos 20 eventos en {lugar} a partir de hoy y las prÃ³ximas semanas, necesito nombre, descripciÃ³n, fecha, lugar, direcciÃ³n, barrio y precio
```

**Selectores verificados**:
```javascript
// 1. Llenar textarea
await puppeteer_fill({ selector: 'textarea', value: prompt });

// 2. Hacer clic en Send (USAR ESTE)
await puppeteer_click({ selector: 'button[aria-label="Send"]' });

// 3. Extraer respuesta (despuÃ©s de esperar)
const content = document.querySelector('.prose')?.innerText;
```

**Manejo de popup de suscripciÃ³n**:
```javascript
// Si aparece pÃ¡gina de suscripciÃ³n, buscar botÃ³n con "gratis"
const buttons = document.querySelectorAll('button');
for (const btn of buttons) {
  if (btn.textContent.toLowerCase().includes('gratis') ||
      btn.textContent.toLowerCase().includes('free')) {
    btn.click();
    break;
  }
}
```

**Formato de respuesta esperado**:
```
Eventos en {lugar} a partir de hoy

1. Nombre del Evento
DescripciÃ³n: ...
Fecha: DD de mes de YYYY
Lugar: ...
DirecciÃ³n: ...
Barrio: ...
Precio: ...

2. Siguiente evento...
```

**Notas importantes**:
- Felo usa 49+ fuentes para buscar informaciÃ³n
- La respuesta tarda 15-30 segundos en generarse
- Genera eventos bien estructurados con todos los campos
- NO requiere login para funcionar

**âš ï¸ PROBLEMAS CONOCIDOS**:
- Felo puede detectar automatizaciÃ³n y generar respuestas incompletas
- Si la respuesta se corta antes de los 20 eventos:
  1. Probar manualmente en el navegador
  2. Reducir la frecuencia de screenshots (causan flickering)
  3. Esperar mÃ¡s tiempo entre requests
  4. Alternar con otros sources (Gemini, Grok)

---

### ğŸŸ£ GROK (grok.com) - âœ… NO REQUIERE AUTH

**URL**: `https://grok.com`

**Paso a paso**:
1. Navegar a la URL con incÃ³gnito + maximizado
2. Esperar 2-3 segundos
3. Llenar el campo de texto:
   - Selector: `textarea`
4. Hacer clic en enviar:
   - Selector: `button[aria-label='Send']`
5. Esperar 15-20 segundos
6. Extraer respuesta:
   - Selector: `.response-text`

**Prompt a usar** (MISMO QUE GEMINI):
```
me podrÃ­as pasar por lo menos 20 eventos, fiestas, festivales, encuentros en {lugar} a partir de hoy y las prÃ³ximas semanas?, si puede ser que incluya su nombre, descripciÃ³n, fecha, lugar, direcciÃ³n, barrio, precio y alguna info extra que tengas! En formato de tabla con tabs separando las columnas: NÂ°	Nombre del Evento	DescripciÃ³n	Fecha	Lugar / DirecciÃ³n	Barrio	Precio (ARS)	Info Extra
```

**Notas**:
- Grok NO requiere autenticaciÃ³n
- Funciona directamente sin login
- Usar el mismo prompt que Gemini para consistencia

**âš ï¸ PROBLEMA CONOCIDO**:
- Grok tiene captcha de Cloudflare que NO se puede automatizar con Puppeteer
- El checkbox estÃ¡ en un iframe protegido
- **SoluciÃ³n**: Usar Gemini como alternativa principal hasta resolver

---

### ğŸŒ BUENOS ALIENS (buenosaliens.com)

**URL**: `https://www.buenosaliens.com/#agenda`

**Tipo**: Scraping tradicional (no AI, solo extraer datos de la pÃ¡gina)

**Paso a paso**:
1. Navegar a la URL
2. Esperar que cargue la agenda (5 segundos)
3. Extraer eventos directamente del DOM:
   - Cards de eventos: `.event-item`
   - TÃ­tulo: `h3.event-title`
   - Fecha: `.event-date`
   - Lugar: `.event-venue`

**NO requiere prompt** - es scraping directo de la pÃ¡gina.

---

## ğŸ”„ ORDEN DE ROTACIÃ“N POR LLAMADO

**âš ï¸ IMPORTANTE: USAR SOLO GEMINI Y FELO (Grok tiene captcha bloqueante)**

Para evitar detecciÃ³n de automatizaciÃ³n, rotar el sitio en CADA llamado:

**Ejemplo para Buenos Aires (ciudad con barrios):**
1. Palermo, Buenos Aires â†’ **Gemini**
2. Recoleta, Buenos Aires â†’ **Felo**
3. San Telmo, Buenos Aires â†’ **Gemini**
4. Belgrano, Buenos Aires â†’ **Felo**
... y asÃ­ alternando

**Ejemplo para ciudades sin barrios:**
1. Buenos Aires â†’ **Gemini**
2. CÃ³rdoba â†’ **Felo**
3. Rosario â†’ **Gemini**
4. Mendoza â†’ **Felo**
... y asÃ­ alternando

**Orden de rotaciÃ³n**: Gemini â†’ Felo â†’ Gemini â†’ Felo (NO usar Grok - tiene captcha)

---

## âš ï¸ TROUBLESHOOTING COMÃšN

### Problema: PÃ¡gina de suscripciÃ³n en Felo
**SoluciÃ³n**: Buscar y clickear botÃ³n con texto "gratis" o "free"

### Problema: Gemini pide login
**SoluciÃ³n**: Refrescar pÃ¡gina o usar nueva ventana incÃ³gnito

### Problema: Timeout en respuesta
**SoluciÃ³n**: Aumentar wait_time en config/sites.json

### Problema: Pantalla negra/vacÃ­a
**SoluciÃ³n**: La pÃ¡gina perdiÃ³ foco, navegar nuevamente a la URL

---

## ğŸ§¹ SCRIPTS DE MANTENIMIENTO

### fix_countries_db.py - Corregir paÃ­ses/provincias en DB existente

Si tienes eventos con paÃ­ses incorrectos (cÃ³digos ISO, Unknown, etc.), ejecutar:

```bash
cd backend/data/scripts
python fix_countries_db.py
```

**QuÃ© hace:**
1. Convierte cÃ³digos ISO a nombres completos (ES â†’ EspaÃ±a, DE â†’ Alemania)
2. Corrige ciudades truncadas (Sao â†’ SÃ£o Paulo, Rio â†’ Rio de Janeiro)
3. Usa `region_utils.py` para mapear ciudad â†’ paÃ­s dinÃ¡micamente
4. Agrega columna `province` si no existe y la llena automÃ¡ticamente

---

**Ãšltima actualizaciÃ³n**: 2025-11-23
**VersiÃ³n**: 1.2.0
**Mantenedor**: Sistema de Eventos
